{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Леса, градиентбустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первая модель, на статистических данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/RomanSivolobtsev/Documents/Статистика АПЛ/\"\n",
    "start_year = 2005\n",
    "start_seasonses = pd.DataFrame() # 2 сезона для начальной выборки генерирования фич\n",
    "train = pd.DataFrame() # 7 сезонов по которым будет обучаться модель \n",
    "test = pd.DataFrame() # 3 сезона для прогнозов\n",
    "\n",
    "for i in range(2):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    E1 = pd.read_csv(folder + 'E1.csv', index_col=False)\n",
    "    E2 = pd.read_csv(folder + 'E2.csv', index_col=False)\n",
    "    E3 = pd.read_csv(folder + 'E3.csv', index_col=False)\n",
    "    start_seasonses = start_seasonses.append([E0, E1, E2, E3], ignore_index=True)\n",
    "\n",
    "for i in range(2, 9):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    E1 = pd.read_csv(folder + 'E1.csv', index_col=False)\n",
    "    E2 = pd.read_csv(folder + 'E2.csv', index_col=False)\n",
    "    E3 = pd.read_csv(folder + 'E3.csv', index_col=False)\n",
    "    train = train.append([E0, E1, E2, E3], ignore_index=True)\n",
    "    \n",
    "for i in range(9, 12):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False) # прогноз ведём только по командам из АПЛ\n",
    "    test = test.append(E0, ignore_index=True)\n",
    "    \n",
    "train = train[pd.notnull(train['Div'])]\n",
    "test = test[pd.notnull(test['Div'])] # некоторые файлы в конце импортируют пустую строчку, эта для их отлова.\n",
    "\n",
    "attribute_common = [\"Div\", \"Date\", \"AwayTeam\", \"HomeTeam\", \"FTHG\", \"FTAG\", \"FTR\", \"Referee\"] #общие признаки матча\n",
    "attribute_statistic = [\"HS\", \"AS\", \"HST\", \"AST\", \"HC\", \"AC\", \"HF\", \"AF\", \"HY\", \"AY\", \"HR\", \"AR\"] #статистические признаки матча\n",
    "attribute_bk = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'WHH', 'WHD', 'WHA',\n",
    "                'VCH', 'VCD', 'VCA'] # букмекерские ставки на события"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.index = [x for x in range(len(test))]\n",
    "train.index = [x for x in range(len(train))] # перебивка индексов, чтобы не было проблем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Referee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>J Moss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>M Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>M Dean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Hull</td>\n",
       "      <td>QPR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>C Pawson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div      Date        AwayTeam    HomeTeam  FTHG  FTAG FTR   Referee\n",
       "0  E0  16/08/14  Crystal Palace     Arsenal   2.0   1.0   H    J Moss\n",
       "1  E0  16/08/14         Everton   Leicester   2.0   2.0   D   M Jones\n",
       "2  E0  16/08/14         Swansea  Man United   1.0   2.0   A    M Dean\n",
       "3  E0  16/08/14            Hull         QPR   0.0   1.0   A  C Pawson\n",
       "4  E0  16/08/14     Aston Villa       Stoke   0.0   1.0   A  A Taylor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[attribute_common][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно предсказывать исход после первого тайма, или точный счёт. Но для начала попробуем предсказывать признак FTR. Для этого нужно нагенерировать фич для каждой из участвующих команд, относительно статистических данных прошедших матчей. Букмекерские признаки пока не рассматриваем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Referee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>J Moss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>M Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>M Dean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Hull</td>\n",
       "      <td>QPR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>C Pawson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E0</td>\n",
       "      <td>16/08/14</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS    AS  HST  AST   HC   AC    HF    AF   HY   AY   HR   AR Div  \\\n",
       "0  14.0   4.0  6.0  2.0  9.0  3.0  13.0  19.0  2.0  2.0  0.0  1.0  E0   \n",
       "1  11.0  13.0  3.0  3.0  3.0  6.0  16.0  10.0  1.0  1.0  0.0  0.0  E0   \n",
       "2  14.0   5.0  5.0  4.0  4.0  0.0  14.0  20.0  2.0  4.0  0.0  0.0  E0   \n",
       "3  19.0  11.0  6.0  4.0  8.0  9.0  10.0  10.0  1.0  2.0  0.0  0.0  E0   \n",
       "4  12.0   7.0  2.0  2.0  2.0  8.0  14.0   9.0  0.0  3.0  0.0  0.0  E0   \n",
       "\n",
       "       Date        AwayTeam    HomeTeam  FTHG  FTAG FTR   Referee  \n",
       "0  16/08/14  Crystal Palace     Arsenal   2.0   1.0   H    J Moss  \n",
       "1  16/08/14         Everton   Leicester   2.0   2.0   D   M Jones  \n",
       "2  16/08/14         Swansea  Man United   1.0   2.0   A    M Dean  \n",
       "3  16/08/14            Hull         QPR   0.0   1.0   A  C Pawson  \n",
       "4  16/08/14     Aston Villa       Stoke   0.0   1.0   A  A Taylor  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[attribute_statistic + attribute_common][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Team1 - Home Team, Team2 - Away Team\n",
    "\n",
    "def generate_statistic_features(Team1_HomeMatch, Team1_AwayMatch, Team2_HomeMatch, Team2_AwayMatch, Referee_Match):\n",
    "    match_significance = np.array([1, 0.75, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05])\n",
    "    match_significance = match_significance/sum(match_significance) # нормировка коэффициентов\n",
    "    \n",
    "    Team1_FTHG_average = Team1_HomeMatch['FTHG'].mean() # среднее количество забитых голов домашней командны в её домашних матчах\n",
    "    Team2_FTAG_average = Team2_AwayMatch['FTAG'].mean() # среднее количество забитых голов гостевой команды в её гостевых матчах \n",
    "    Team1_FTHG_nearest = sum(Team1_HomeMatch['FTHG'][-10:]*match_significance) # количество забитых голов домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_FTAG_nearest = sum(Team2_AwayMatch['FTAG'][-10:]*match_significance) # количество забитых голов гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "    \n",
    "    Team1_FTHG_average = Team1_AwayMatch['FTHG'].mean() # среднее количество пропущенных голов домашней командны в её домашних матчах\n",
    "    Team2_FTAG_average = Team2_HomeMatch['FTAG'].mean() # среднее количество пропущенных голов гостевой команды в её гостевых матчах \n",
    "    Team1_FTHG_nearest = sum(Team1_AwayMatch['FTHG'][-10:]*match_significance) # количество пропущенных голов домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_FTAG_nearest = sum(Team2_HomeMatch['FTAG'][-10:]*match_significance) # количество пропущенных голов гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "    \n",
    "    Team1_HS_nearest = sum(Team1_HomeMatch['HS'][-10:]*match_significance) # количество ударов по воротам домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AS_nearest = sum(Team2_AwayMatch['AS'][-10:]*match_significance) # количество ударов по воротам гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "    \n",
    "    Team1_HST_nearest = sum(Team1_HomeMatch['HST'][-10:]*match_significance) # количество ударов в створ ворот домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AST_nearest = sum(Team2_AwayMatch['AST'][-10:]*match_significance) # количество ударов в створ ворот гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "\n",
    "    Team1_HC_nearest = sum(Team1_HomeMatch['HC'][-10:]*match_significance) # количество угловых домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AC_nearest = sum(Team2_AwayMatch['AC'][-10:]*match_significance) # количество угловых гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости   \n",
    "\n",
    "    Team1_HF_nearest = sum(Team1_HomeMatch['HF'][-10:]*match_significance) # количество фолов домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AF_nearest = sum(Team2_AwayMatch['AF'][-10:]*match_significance) # количество фолов гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "\n",
    "    Team1_HY_nearest = sum(Team1_HomeMatch['HY'][-10:]*match_significance) # количество жёлтых карточек домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AY_nearest = sum(Team2_AwayMatch['AY'][-10:]*match_significance) # количество жёлтых карточек гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "\n",
    "    Team1_HR_nearest = sum(Team1_HomeMatch['HR'][-10:]*match_significance) # количество красных карточек домашней командны в её последних 10 домашних матчах с коэфициентами значимости\n",
    "    Team2_AR_nearest = sum(Team2_AwayMatch['AR'][-10:]*match_significance) # количество красных карточек гостевой команды в её последних 10 гостевых матчах с коэфициентами значимости\n",
    "    \n",
    "    Team1_HFTR_nearest = sum(Team1_HomeMatch['FTR'][-20:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 матчей \n",
    "    Team2_AFTR_nearest = sum(Team2_AwayMatch['FTR'][-20:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 матчей\n",
    "                            \n",
    "    Referee_FTG_average = Referee_Match['FTHG'].mean() + Referee_Match['FTAG'].mean() # cреднее количество забитых голов в матчах, которые обслуживал этот судья\n",
    "    Referee_S_average = Referee_Match['HS'].mean() + Referee_Match['AS'].mean() # cреднее количество ударов по воротам в матчах, которые обслуживал этот судья\n",
    "    Referee_ST_average = Referee_Match['HST'].mean() + Referee_Match['AST'].mean() # cреднее количество ударов в створ ворот в матчах, которые обслуживал этот судья\n",
    "    Referee_C_average = Referee_Match['HC'].mean() + Referee_Match['AC'].mean() # cреднее количество угловых в матчах, которые обслуживал этот судья\n",
    "    Referee_F_average = Referee_Match['HF'].mean() + Referee_Match['AF'].mean() # cреднее количество фолов в матчах, которые обслуживал этот судья\n",
    "    Referee_Y_average = Referee_Match['HY'].mean() + Referee_Match['AY'].mean() # cреднее количество желтых карточек в матчах, которые обслуживал этот судья\n",
    "    Referee_R_average = Referee_Match['HR'].mean() + Referee_Match['AR'].mean() # cреднее количество красных карточек в матчах, которые обслуживал этот судья\n",
    "\n",
    "    return [Team1_FTHG_average, Team2_FTAG_average, Team1_FTHG_nearest, Team2_FTAG_nearest, Team1_FTHG_average, \n",
    "            Team2_FTAG_average,Team1_FTHG_nearest, Team2_FTAG_nearest, Team1_HS_nearest, Team2_AS_nearest, \n",
    "            Team1_HST_nearest, Team2_AST_nearest, Team1_HC_nearest, Team2_AC_nearest, Team1_HF_nearest, Team2_AF_nearest,\n",
    "            Team1_HY_nearest, Team2_AY_nearest, Team1_HR_nearest, Team2_AR_nearest, Team1_HFTR_nearest, Team2_AFTR_nearest,\n",
    "            Referee_FTG_average, Referee_S_average, Referee_ST_average, Referee_C_average, Referee_F_average,\n",
    "            Referee_Y_average, Referee_R_average]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Teams = train['HomeTeam'].append(test['HomeTeam']).unique() # Список всех команд за 10 лет в 4 английских дивизионах\n",
    "Teams_HomeData = {Teams[i]: start_seasonses[start_seasonses[\"HomeTeam\"] == Teams[i]] for i in range(len(Teams))} # домашние матчи каждой прогназируемой команды\n",
    "Teams_AwayData = {Teams[i]: start_seasonses[start_seasonses[\"AwayTeam\"] == Teams[i]] for i in range(len(Teams))} # гостевые матчи каждой прогназируемой команды\n",
    "\n",
    "Referees = train['Referee'].append(test['Referee']).unique()\n",
    "Referees_Data = {Referees[i]: start_seasonses[start_seasonses[\"Referee\"] == Referees[i]] for i in range(len(Referees))} # матчи каждого рефери\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015625953674316406\n"
     ]
    }
   ],
   "source": [
    "# время на подсчёт вычисления фич для одного матча\n",
    "\n",
    "start = time.time()\n",
    "generate_statistic_features(Teams_HomeData[\"Arsenal\"], Teams_AwayData[\"Arsenal\"], Teams_HomeData[\"Liverpool\"], \n",
    "                            Teams_AwayData[\"Liverpool\"], Referees_Data[\"A Taylor\"])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>BbMx&gt;2.5</th>\n",
       "      <th>BbAv&gt;2.5</th>\n",
       "      <th>BbMx&lt;2.5</th>\n",
       "      <th>BbAv&lt;2.5</th>\n",
       "      <th>BbAH</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>BbMxAHH</th>\n",
       "      <th>BbAvAHH</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbAvAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>E0</td>\n",
       "      <td>23/12/06</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.82</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>E0</td>\n",
       "      <td>02/01/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.13</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>E0</td>\n",
       "      <td>21/01/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Man United</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.65</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>E0</td>\n",
       "      <td>11/02/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Wigan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.03</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>E0</td>\n",
       "      <td>03/03/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Reading</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.95</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>E0</td>\n",
       "      <td>07/04/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.91</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/04/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.72</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>E0</td>\n",
       "      <td>17/04/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Man City</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.86</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>E0</td>\n",
       "      <td>29/04/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.95</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>E0</td>\n",
       "      <td>06/05/07</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Div      Date HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "2215  E0  23/12/06  Arsenal   Blackburn     6     2   H     3     1   H   \n",
       "2252  E0  02/01/07  Arsenal    Charlton     4     0   H     2     0   H   \n",
       "2272  E0  21/01/07  Arsenal  Man United     2     1   H     0     0   D   \n",
       "2301  E0  11/02/07  Arsenal       Wigan     2     1   H     0     1   A   \n",
       "2313  E0  03/03/07  Arsenal     Reading     2     1   H     0     0   D   \n",
       "2347  E0  07/04/07  Arsenal    West Ham     0     1   A     0     1   A   \n",
       "2361  E0  14/04/07  Arsenal      Bolton     2     1   H     1     1   D   \n",
       "2369  E0  17/04/07  Arsenal    Man City     3     1   H     1     1   D   \n",
       "2392  E0  29/04/07  Arsenal      Fulham     3     1   H     1     0   H   \n",
       "2402  E0  06/05/07  Arsenal     Chelsea     1     1   D     1     0   H   \n",
       "\n",
       "       ...    BbMx>2.5  BbAv>2.5  BbMx<2.5  BbAv<2.5  BbAH  BbAHh  BbMxAHH  \\\n",
       "2215   ...        2.05      1.91      1.91      1.82  26.0  -1.25     1.95   \n",
       "2252   ...        1.70      1.62      2.35      2.13  22.0  -1.75     2.12   \n",
       "2272   ...        2.25      2.10      1.74      1.65  27.0   0.00     1.85   \n",
       "2301   ...        1.80      1.72      2.17      2.03  27.0  -1.50     1.90   \n",
       "2313   ...        1.90      1.78      2.14      1.95  27.0  -1.00     1.96   \n",
       "2347   ...        1.91      1.82      2.01      1.91  26.0  -1.25     2.04   \n",
       "2361   ...        2.25      2.00      1.80      1.72  22.0  -0.75     1.95   \n",
       "2369   ...        2.04      1.88      1.94      1.86  31.0  -1.25     2.10   \n",
       "2392   ...        1.91      1.76      2.10      1.95  30.0  -1.25     1.96   \n",
       "2402   ...        2.20      2.05      1.75      1.69  28.0   0.00     2.05   \n",
       "\n",
       "      BbAvAHH  BbMxAHA  BbAvAHA  \n",
       "2215     1.90     2.03     1.97  \n",
       "2252     2.03     1.87     1.83  \n",
       "2272     1.79     2.15     2.01  \n",
       "2301     1.84     2.12     2.00  \n",
       "2313     1.87     2.04     1.97  \n",
       "2347     2.02     1.89     1.85  \n",
       "2361     1.93     2.00     1.95  \n",
       "2369     2.07     1.88     1.83  \n",
       "2392     1.87     2.08     1.99  \n",
       "2402     1.99     1.89     1.80  \n",
       "\n",
       "[10 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Teams_HomeData[\"Arsenal\"][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9736842105263158,\n",
       " 0.39473684210526316,\n",
       " 0.91891891891891897,\n",
       " 0.14864864864864866,\n",
       " 0.9736842105263158,\n",
       " 0.39473684210526316,\n",
       " 0.91891891891891897,\n",
       " 0.14864864864864866,\n",
       " 16.756756756756758,\n",
       " 14.094594594594597,\n",
       " 9.9054054054054053,\n",
       " 8.378378378378379,\n",
       " 8.5405405405405421,\n",
       " 6.1216216216216228,\n",
       " 11.594594594594595,\n",
       " 11.905405405405407,\n",
       " 1.8513513513513518,\n",
       " 1.1216216216216217,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 45,\n",
       " 25,\n",
       " 1.6956521739130435,\n",
       " 20.608695652173914,\n",
       " 10.695652173913043,\n",
       " 10.043478260869566,\n",
       " 24.826086956521742,\n",
       " 3.0869565217391304,\n",
       " 0.17391304347826086]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_statistic_features(Teams_HomeData[\"Arsenal\"], Teams_AwayData[\"Arsenal\"], Teams_HomeData[\"Liverpool\"], Teams_AwayData[\"Liverpool\"], Referees_Data[\"A Taylor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"Team1_FTHG_average\", \"Team2_FTAG_average\", \"Team1_FTHG_nearest\", \"Team2_FTAG_nearest\", \"Team1_FTHG_average\", \n",
    "           \"Team2_FTAG_average\",\"Team1_FTHG_nearest\", \"Team2_FTAG_nearest\", \"Team1_HS_nearest\", \"Team2_AS_nearest\", \n",
    "           \"Team1_HST_nearest\", \"Team2_AST_nearest\", \"Team1_HC_nearest\", \"Team2_AC_nearest\", \"Team1_HF_nearest\", \n",
    "           \"Team2_AF_nearest\", \"Team1_HY_nearest\", \"Team2_AY_nearest\", \"Team1_HR_nearest\", \"Team2_AR_nearest\",\n",
    "           \"Team1_HFTR_nearest\", \"Team2_AFTR_nearest\", \"Referee_FTG_average\", \"Referee_S_average\", \"Referee_ST_average\",\n",
    "           \"Referee_C_average\", \"Referee_F_average\", \"Referee_Y_average\", \"Referee_R_average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(columns = features)\n",
    "train_Y = []\n",
    "test_X = pd.DataFrame(columns = features)\n",
    "test_Y = test[\"FTR\"]\n",
    "\n",
    "# выборка на 8 сезонах для обучения\n",
    "\n",
    "for i in range(len(train)):\n",
    "    row = train.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    \n",
    "    if (len(Teams_HomeData[Team1]) >= 20) & (len(Teams_AwayData[Team2]) >= 20) & (len(Referees_Data[Referee]) >= 5):\n",
    "    # если команда только влетела в каком-то сезоне, то на неё нет никакой информации\n",
    "        feature = generate_statistic_features(Teams_HomeData[Team1], Teams_AwayData[Team1], Teams_HomeData[Team2], Teams_AwayData[Team2], Referees_Data[Referee])\n",
    "        train_X.loc[i] = feature\n",
    "        train_Y.append(train[\"FTR\"].loc[i])\n",
    "        \n",
    "    Teams_HomeData[Team1] = Teams_HomeData[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData[Team2] = Teams_AwayData[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data[Referee] = Referees_Data[Referee].append(row, ignore_index=True)\n",
    "\n",
    "# выборка на 2 неполных сезонах для построения прогнозов\n",
    "\n",
    "for i in range(len(test)):\n",
    "    row = test.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    \n",
    "    feature = generate_statistic_features(Teams_HomeData[Team1], Teams_AwayData[Team1], Teams_HomeData[Team2], Teams_AwayData[Team2], Referees_Data[Referee])\n",
    "    test_X.loc[i] = feature\n",
    "    Teams_HomeData[Team1] = Teams_HomeData[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData[Team2] = Teams_AwayData[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data[Referee] = Referees_Data[Referee].append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_X.replace(to_replace=\"NaN\", value=0) # это не повлияет на результаты, так как в фичах берётся максимум из всех БК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.04, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=50, min_samples_split=1,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [2, 3, 4], 'learning_rate': [0.02, 0.03, 0.04],\n",
    "                     'min_samples_leaf':[30, 50, 70], 'n_estimators': [30, 50, 70]}]\n",
    "\n",
    "GB_classifier = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier.fit(train_X, train_Y)\n",
    "print(GB_classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.03, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=50, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=0.9, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_classifier = GradientBoostingClassifier(min_samples_split = 2, max_depth = 3, learning_rate = 0.03,\n",
    "                                           min_samples_leaf = 50, n_estimators = 50, subsample=0.9)\n",
    "GB_classifier.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>Team1_FTHG_nearest</th>\n",
       "      <th>Team2_FTAG_nearest</th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>Team1_FTHG_nearest</th>\n",
       "      <th>Team2_FTAG_nearest</th>\n",
       "      <th>Team1_HS_nearest</th>\n",
       "      <th>Team2_AS_nearest</th>\n",
       "      <th>...</th>\n",
       "      <th>Team2_AR_nearest</th>\n",
       "      <th>Team1_HFTR_nearest</th>\n",
       "      <th>Team2_AFTR_nearest</th>\n",
       "      <th>Referee_FTG_average</th>\n",
       "      <th>Referee_S_average</th>\n",
       "      <th>Referee_ST_average</th>\n",
       "      <th>Referee_C_average</th>\n",
       "      <th>Referee_F_average</th>\n",
       "      <th>Referee_Y_average</th>\n",
       "      <th>Referee_R_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030005</td>\n",
       "      <td>0.054644</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.038357</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0.017611</td>\n",
       "      <td>0.057483</td>\n",
       "      <td>0.064695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.158866</td>\n",
       "      <td>0.106836</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>0.015943</td>\n",
       "      <td>0.029466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1_FTHG_average  Team2_FTAG_average  Team1_FTHG_nearest  \\\n",
       "0            0.030005            0.054644            0.021821   \n",
       "\n",
       "   Team2_FTAG_nearest  Team1_FTHG_average  Team2_FTAG_average  \\\n",
       "0            0.018047            0.027482            0.038357   \n",
       "\n",
       "   Team1_FTHG_nearest  Team2_FTAG_nearest  Team1_HS_nearest  Team2_AS_nearest  \\\n",
       "0            0.021185            0.017611          0.057483          0.064695   \n",
       "\n",
       "         ...          Team2_AR_nearest  Team1_HFTR_nearest  \\\n",
       "0        ...                  0.006756            0.158866   \n",
       "\n",
       "   Team2_AFTR_nearest  Referee_FTG_average  Referee_S_average  \\\n",
       "0            0.106836             0.019682           0.052134   \n",
       "\n",
       "   Referee_ST_average  Referee_C_average  Referee_F_average  \\\n",
       "0             0.01588           0.013332           0.018585   \n",
       "\n",
       "   Referee_Y_average  Referee_R_average  \n",
       "0           0.015943           0.029466  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([GB_classifier.feature_importances_], columns = train_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главные фичи - колличество набранных очков за последние 20 матчей домашней и гостевой командами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.462789150839\n",
      "На тестовой выборке: 0.517543859649\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>H_prob</th>\n",
       "      <th>prediction</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213273</td>\n",
       "      <td>0.245350</td>\n",
       "      <td>0.541377</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.261708</td>\n",
       "      <td>0.475731</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247637</td>\n",
       "      <td>0.295854</td>\n",
       "      <td>0.456509</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.237212</td>\n",
       "      <td>0.287030</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.261695</td>\n",
       "      <td>0.287030</td>\n",
       "      <td>0.451275</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.339337</td>\n",
       "      <td>0.296012</td>\n",
       "      <td>0.364652</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.375117</td>\n",
       "      <td>0.286748</td>\n",
       "      <td>0.338135</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.182276</td>\n",
       "      <td>0.217258</td>\n",
       "      <td>0.600466</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.419620</td>\n",
       "      <td>0.294669</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.298086</td>\n",
       "      <td>0.250005</td>\n",
       "      <td>0.451909</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.348225</td>\n",
       "      <td>0.308125</td>\n",
       "      <td>0.343650</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.195077</td>\n",
       "      <td>0.245562</td>\n",
       "      <td>0.559361</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.279967</td>\n",
       "      <td>0.279432</td>\n",
       "      <td>0.440601</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.294836</td>\n",
       "      <td>0.280405</td>\n",
       "      <td>0.424759</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.303650</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_prob    D_prob    H_prob prediction result\n",
       "0   0.213273  0.245350  0.541377          H      H\n",
       "1   0.262561  0.261708  0.475731          H      D\n",
       "2   0.247637  0.295854  0.456509          H      A\n",
       "3   0.237212  0.287030  0.475758          H      A\n",
       "4   0.261695  0.287030  0.451275          H      A\n",
       "5   0.339337  0.296012  0.364652          H      D\n",
       "6   0.375117  0.286748  0.338135          A      A\n",
       "7   0.182276  0.217258  0.600466          H      H\n",
       "8   0.419620  0.294669  0.285712          A      A\n",
       "9   0.298086  0.250005  0.451909          H      A\n",
       "10  0.348225  0.308125  0.343650          A      D\n",
       "11  0.195077  0.245562  0.559361          H      H\n",
       "12  0.279967  0.279432  0.440601          H      A\n",
       "13  0.294836  0.280405  0.424759          H      D\n",
       "14  0.288490  0.303650  0.407861          H      D"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y, GB_classifier.predict(train_X))))\n",
    "\n",
    "proba_GB = GB_classifier.predict_proba(test_X)\n",
    "prediction_GB = GB_classifier.predict(test_X)\n",
    "\n",
    "result_GB = pd.DataFrame()\n",
    "result_GB[0] = proba_GB[:,0]\n",
    "result_GB[1] = proba_GB[:,1]\n",
    "result_GB[2] = proba_GB[:,2]\n",
    "result_GB[3] = prediction_GB\n",
    "result_GB[4] = test_Y\n",
    "\n",
    "result_GB.columns = [\"A_prob\", \"D_prob\", \"H_prob\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB = accuracy_score(test_Y, result_GB[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB))\n",
    "\n",
    "result_GB[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H    842\n",
       "A    296\n",
       "D      2\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_GB[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H    516\n",
       "A    340\n",
       "D    284\n",
       "Name: FTR, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"FTR\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за объёмов выборки(несколько лиг) и большого количества шума, модель плохо обучается. Попробуем ужать выборку и выкинуть ненужные фичи типо красных карточек заработанных командой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вторая модель, на модернизированных статистических данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/RomanSivolobtsev/Documents/Статистика АПЛ/\"\n",
    "start_year = 2005\n",
    "start_seasonses2 = pd.DataFrame() # 2 сезона для начальной выборки генерирования фич\n",
    "train2 = pd.DataFrame() # 7 сезонов по которым будет обучаться модель \n",
    "test2 = pd.DataFrame() # 3 сезона для прогнозов\n",
    "\n",
    "for i in range(2):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    E1 = pd.read_csv(folder + 'E1.csv', index_col=False)\n",
    "    E2 = pd.read_csv(folder + 'E2.csv', index_col=False)\n",
    "    E3 = pd.read_csv(folder + 'E3.csv', index_col=False)\n",
    "    start_seasonses2 = start_seasonses2.append([E0, E1, E2, E3], ignore_index=True)\n",
    "\n",
    "for i in range(2, 9):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    train2 = train2.append([E0], ignore_index=True)\n",
    "    \n",
    "for i in range(9, 12):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False) # прогноз ведём только по командам из АПЛ\n",
    "    test2 = test2.append(E0, ignore_index=True)\n",
    "    \n",
    "train2 = train2[pd.notnull(train2['Div'])]\n",
    "test2 = test2[pd.notnull(test2['Div'])] # некоторые файлы в конце импортируют пустую строчку, эта для их отлова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2.index = [x for x in range(len(test2))]\n",
    "train2.index = [x for x in range(len(train2))] # перебивка индексов, чтобы не было проблем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team1 - Home Team, Team2 - Away Team\n",
    "\n",
    "def generate_statistics_features2(Team1_HomeMatch, Team1_AwayMatch, Team2_HomeMatch, Team2_AwayMatch, Referee_Match, BK):\n",
    "    match_significance = np.array([1, 0.7, 0.5, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05])\n",
    "    match_significance = match_significance/sum(match_significance) # нормировка коэффициентов\n",
    "    \n",
    "    Team1_FTHG_average = Team1_HomeMatch['FTHG'].mean() # среднее количество забитых голов домашней командны в её домашних матчах\n",
    "    Team2_FTAG_average = Team2_AwayMatch['FTAG'].mean() # среднее количество забитых голов гостевой команды в её гостевых матчах \n",
    "    FTG_nearest_diff = sum(Team1_HomeMatch['FTHG'][-10:]*match_significance) - sum(Team2_AwayMatch['FTAG'][-10:]*match_significance)\n",
    "   \n",
    "    FTLG_nearest_diff = sum(Team1_AwayMatch['FTHG'][-10:]*match_significance)-sum(Team2_HomeMatch['FTAG'][-10:]*match_significance) \n",
    "    # разница пропущенных голов домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    S_nearest_diff = sum(Team1_HomeMatch['HS'][-10:]*match_significance)-sum(Team2_AwayMatch['AS'][-10:]*match_significance) \n",
    "    # разница ударов по воротам домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    ST_nearest_diff = sum(Team1_HomeMatch['HST'][-10:]*match_significance) - sum(Team2_AwayMatch['AST'][-10:]*match_significance) \n",
    "    # разница ударов в створ ворот домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "\n",
    "    C_nearest_diff = sum(Team1_HomeMatch['HC'][-10:]*match_significance) -sum(Team2_AwayMatch['AC'][-10:]*match_significance) \n",
    "    # разница угловых домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости   \n",
    "\n",
    "    Team1_HFTR_nearest = sum(Team1_HomeMatch['FTR'][-5:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 домашних матчей \n",
    "    Team2_AFTR_nearest = sum(Team2_AwayMatch['FTR'][-5:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 гостевых матчей\n",
    "     \n",
    "    Team1_HFTR_nearest2 = sum(Team1_HomeMatch['FTR'][-15:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 домашних матчей \n",
    "    Team2_AFTR_nearest2 = sum(Team2_AwayMatch['FTR'][-15:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 гостевых матчей\n",
    "                     \n",
    "    Team1_HFTR_nearest3 = sum(Team1_HomeMatch['FTR'][-30:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 домашних матчей \n",
    "    Team2_AFTR_nearest3 = sum(Team2_AwayMatch['FTR'][-30:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 гостевых матчей\n",
    "                     \n",
    "    Referee_HomeTeam_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[1, 0, 0]).mean() # процент побед домашних команд в последних 10 матчах судьи \n",
    "    Referee_AwayTeam_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[0, 0, 1]).mean() # процент ничейных результатов в последних 10 матчах судьи \n",
    "    Referee_Draw_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[0, 1, 0]).mean()     # процент побед гостевых команд в последних 10 матчах судьи \n",
    "\n",
    "    return [Team1_FTHG_average, Team2_FTAG_average, FTG_nearest_diff, FTLG_nearest_diff, S_nearest_diff, ST_nearest_diff, \n",
    "            C_nearest_diff, Team1_HFTR_nearest, Team2_AFTR_nearest, Team1_HFTR_nearest2, Team2_AFTR_nearest2,\n",
    "            Team1_HFTR_nearest3, Team2_AFTR_nearest3, Referee_HomeTeam_points, Referee_AwayTeam_points, Referee_Draw_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features2 = [\"Team1_FTHG_average\", \"Team2_FTAG_average\", \"FTG_nearest_diff\", \"FTLG_nearest_diff\", \"S_nearest_diff\", \"ST_nearest_diff\", \n",
    "             \"C_nearest_diff\", \"Team1_HFTR_nearest\", \"Team2_AFTR_nearest\", \"Team1_HFTR_nearest2\", \"Team2_AFTR_nearest2\",\n",
    "             \"Team1_HFTR_nearest3\", \"Team2_AFTR_nearest3\", \"Referee_HomeTeam_points\", \"Referee_AwayTeam_points\",\n",
    "             \"Referee_Draw_points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Teams2 = train2['HomeTeam'].append(test2['HomeTeam']).unique() # Список всех команд за 8 лет в 2 английских дивизионах\n",
    "Teams_HomeData2 = {Teams2[i]: start_seasonses2[start_seasonses2[\"HomeTeam\"] == Teams2[i]] for i in range(len(Teams2))} # домашние матчи каждой прогназируемой команды\n",
    "Teams_AwayData2 = {Teams2[i]: start_seasonses2[start_seasonses2[\"AwayTeam\"] == Teams2[i]] for i in range(len(Teams2))} # гостевые матчи каждой прогназируемой команды\n",
    "\n",
    "Referees2 = train2['Referee'].append(test2['Referee']).unique()\n",
    "Referees_Data2 = {Referees2[i]: start_seasonses2[start_seasonses2[\"Referee\"] == Referees2[i]] for i in range(len(Referees2))} # матчи каждого рефери\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X2 = pd.DataFrame(columns = features2)\n",
    "train_Y2 = []\n",
    "test_X2 = pd.DataFrame(columns = features2)\n",
    "test_Y2 = test2[\"FTR\"]\n",
    "\n",
    "# выборка на 7 сезонах для обучения\n",
    "\n",
    "for i in range(len(train2)):\n",
    "    row = train2.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    \n",
    "    if (len(Teams_HomeData2[Team1]) >= 10) & (len(Teams_AwayData2[Team2]) >= 10) & (len(Referees_Data2[Referee]) >= 10):\n",
    "    # если команда только влетела в каком-то сезоне, то на неё нет достаточно информации\n",
    "        BK =  row[attribute_bk]\n",
    "        feature = generate_statistics_features2(Teams_HomeData2[Team1], Teams_AwayData2[Team1], Teams_HomeData2[Team2], \n",
    "                                                Teams_AwayData2[Team2], Referees_Data2[Referee], BK)\n",
    "        train_X2.loc[i] = feature\n",
    "        train_Y2.append(train2[\"FTR\"].loc[i])\n",
    "        \n",
    "    Teams_HomeData2[Team1] = Teams_HomeData2[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData2[Team2] = Teams_AwayData2[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data2[Referee] = Referees_Data2[Referee].append(row, ignore_index=True)\n",
    "\n",
    "# выборка на 3 неполных сезонах для построения прогнозов\n",
    "\n",
    "for i in range(len(test2)):\n",
    "    row = test2.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    BK =  row[attribute_bk]\n",
    "    \n",
    "    feature = generate_statistics_features2(Teams_HomeData2[Team1], Teams_AwayData2[Team1], Teams_HomeData2[Team2], \n",
    "                                            Teams_AwayData2[Team2], Referees_Data2[Referee], BK)\n",
    "    test_X2.loc[i] = feature\n",
    "    Teams_HomeData2[Team1] = Teams_HomeData2[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData2[Team2] = Teams_AwayData2[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data2[Referee] = Referees_Data2[Referee].append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X2 = test_X2.replace(to_replace=\"NaN\", value=0) # это не повлияет на результаты, так как в фичах берётся максимум из всех БК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.03, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=25, min_samples_split=1,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [2, 3, 4], 'learning_rate': [0.02, 0.03, 0.04],\n",
    "                     'min_samples_leaf':[25, 50, 75], 'n_estimators': [30, 50, 70]}]\n",
    "\n",
    "GB_classifier2 = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier2.fit(train_X2, train_Y2)\n",
    "print(GB_classifier2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.540964777948\n",
      "На тестовой выборке: 0.524561403509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>H</th>\n",
       "      <th>prediction</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.268742</td>\n",
       "      <td>0.276071</td>\n",
       "      <td>0.455186</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.306154</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.345419</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.246777</td>\n",
       "      <td>0.312169</td>\n",
       "      <td>0.441055</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.503614</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>0.240049</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.227697</td>\n",
       "      <td>0.288311</td>\n",
       "      <td>0.483992</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.308813</td>\n",
       "      <td>0.295967</td>\n",
       "      <td>0.395220</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.273301</td>\n",
       "      <td>0.400612</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.502237</td>\n",
       "      <td>0.262989</td>\n",
       "      <td>0.234773</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.262757</td>\n",
       "      <td>0.275821</td>\n",
       "      <td>0.461421</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.264117</td>\n",
       "      <td>0.297812</td>\n",
       "      <td>0.438071</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.291291</td>\n",
       "      <td>0.272336</td>\n",
       "      <td>0.436373</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.178581</td>\n",
       "      <td>0.158974</td>\n",
       "      <td>0.662445</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.190523</td>\n",
       "      <td>0.278397</td>\n",
       "      <td>0.531080</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.289376</td>\n",
       "      <td>0.298573</td>\n",
       "      <td>0.412052</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.206140</td>\n",
       "      <td>0.185048</td>\n",
       "      <td>0.608812</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         D         H prediction result\n",
       "100  0.268742  0.276071  0.455186          H      H\n",
       "101  0.306154  0.348428  0.345419          D      A\n",
       "102  0.246777  0.312169  0.441055          H      H\n",
       "103  0.503614  0.256338  0.240049          A      D\n",
       "104  0.227697  0.288311  0.483992          H      H\n",
       "105  0.308813  0.295967  0.395220          H      D\n",
       "106  0.326087  0.273301  0.400612          H      D\n",
       "107  0.502237  0.262989  0.234773          A      H\n",
       "108  0.262757  0.275821  0.461421          H      A\n",
       "109  0.264117  0.297812  0.438071          H      A\n",
       "110  0.291291  0.272336  0.436373          H      A\n",
       "111  0.178581  0.158974  0.662445          H      H\n",
       "112  0.190523  0.278397  0.531080          H      H\n",
       "113  0.289376  0.298573  0.412052          H      D\n",
       "114  0.206140  0.185048  0.608812          H      H"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_classifier2 = GradientBoostingClassifier(min_samples_split = 1, max_depth = 3, learning_rate = 0.03, \n",
    "                                            random_state = 42, min_samples_leaf = 25, n_estimators = 30)\n",
    "GB_classifier2.fit(train_X2, train_Y2)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y2, GB_classifier2.predict(train_X2))))\n",
    "\n",
    "proba_GB2 = GB_classifier2.predict_proba(test_X2)\n",
    "prediction_GB2 = GB_classifier2.predict(test_X2)\n",
    "\n",
    "result_GB2 = pd.DataFrame()\n",
    "result_GB2[0] = proba_GB2[:,0]\n",
    "result_GB2[1] = proba_GB2[:,1]\n",
    "result_GB2[2] = proba_GB2[:,2]\n",
    "result_GB2[3] = prediction_GB2\n",
    "result_GB2[4] = test_Y2\n",
    "\n",
    "result_GB2.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB2 = accuracy_score(test_Y2, result_GB2[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB2))\n",
    "\n",
    "result_GB2[100:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>FTG_nearest_diff</th>\n",
       "      <th>FTLG_nearest_diff</th>\n",
       "      <th>S_nearest_diff</th>\n",
       "      <th>ST_nearest_diff</th>\n",
       "      <th>C_nearest_diff</th>\n",
       "      <th>Team1_HFTR_nearest</th>\n",
       "      <th>Team2_AFTR_nearest</th>\n",
       "      <th>Team1_HFTR_nearest2</th>\n",
       "      <th>Team2_AFTR_nearest2</th>\n",
       "      <th>Team1_HFTR_nearest3</th>\n",
       "      <th>Team2_AFTR_nearest3</th>\n",
       "      <th>Referee_HomeTeam_points</th>\n",
       "      <th>Referee_AwayTeam_points</th>\n",
       "      <th>Referee_Draw_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.095068</td>\n",
       "      <td>0.080266</td>\n",
       "      <td>0.149117</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.034373</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.192861</td>\n",
       "      <td>0.208487</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.008513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1_FTHG_average  Team2_FTAG_average  FTG_nearest_diff  \\\n",
       "0            0.053299            0.056274          0.025265   \n",
       "\n",
       "   FTLG_nearest_diff  S_nearest_diff  ST_nearest_diff  C_nearest_diff  \\\n",
       "0           0.095068        0.080266         0.149117        0.028472   \n",
       "\n",
       "   Team1_HFTR_nearest  Team2_AFTR_nearest  Team1_HFTR_nearest2  \\\n",
       "0            0.025056            0.008444             0.034373   \n",
       "\n",
       "   Team2_AFTR_nearest2  Team1_HFTR_nearest3  Team2_AFTR_nearest3  \\\n",
       "0             0.002671             0.192861             0.208487   \n",
       "\n",
       "   Referee_HomeTeam_points  Referee_AwayTeam_points  Referee_Draw_points  \n",
       "0                 0.018238                 0.013597             0.008513  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([GB_classifier2.feature_importances_], columns = train_X2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки, в этой выборке параметр количества набранных очков за последние 10 игр был разбит на три: за 5, 15 и 30 игр. Оказалось, что параметр за 30 игр имеет большой вес, а предыдущие не имеют осбого смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H    838\n",
       "A    294\n",
       "D      8\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_GB2[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152,   1, 187],\n",
       "       [ 71,   4, 209],\n",
       "       [ 71,   3, 442]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_Y2, result_GB2[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор в отрез отказывается предсказывать ничьи. Попробуем урезать выборку, заменить парные параметры на их разность(например смотреть не количество очков команд за последние 20 туров, а разницу между двумя командами), а также добавим параметры отвечающие за ставки букмекеров на исходы HomeTeamWin, Draw, AwayTeamWin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Третья модель, на модернизированных статистических данных + коэффициентов БК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/RomanSivolobtsev/Documents/Статистика АПЛ/\"\n",
    "start_year = 2005\n",
    "start_seasonses3 = pd.DataFrame() # 2 сезона для начальной выборки генерирования фич\n",
    "train3 = pd.DataFrame() # 7 сезонов по которым будет обучаться модель \n",
    "test3 = pd.DataFrame() # 3 сезона для прогнозов\n",
    "\n",
    "for i in range(2):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    E1 = pd.read_csv(folder + 'E1.csv', index_col=False)\n",
    "    E2 = pd.read_csv(folder + 'E2.csv', index_col=False)\n",
    "    E3 = pd.read_csv(folder + 'E3.csv', index_col=False)\n",
    "    start_seasonses3 = start_seasonses3.append([E0, E1, E2, E3], ignore_index=True)\n",
    "\n",
    "for i in range(2, 9):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False)\n",
    "    train3 = train3.append([E0], ignore_index=True)\n",
    "    \n",
    "for i in range(9, 12):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    E0 = pd.read_csv(folder + 'E0.csv', index_col=False) # прогноз ведём только по командам из АПЛ\n",
    "    test3 = test3.append(E0, ignore_index=True)\n",
    "    \n",
    "train3 = train3[pd.notnull(train3['Div'])]\n",
    "test3 = test3[pd.notnull(test3['Div'])] # некоторые файлы в конце импортируют пустую строчку, эта для их отлова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3.index = [x for x in range(len(test3))]\n",
    "train3.index = [x for x in range(len(train3))] # перебивка индексов, чтобы не было проблем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team1 - Home Team, Team2 - Away Team\n",
    "\n",
    "def generate_mix_features(Team1_HomeMatch, Team1_AwayMatch, Team2_HomeMatch, Team2_AwayMatch, Referee_Match, BK):\n",
    "    match_significance = np.array([1, 0.7, 0.5, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05])\n",
    "    match_significance = match_significance/sum(match_significance) # нормировка коэффициентов\n",
    "    \n",
    "    Team1_FTHG_average = Team1_HomeMatch['FTHG'].mean() # среднее количество забитых голов домашней командны в её домашних матчах\n",
    "    Team2_FTAG_average = Team2_AwayMatch['FTAG'].mean() # среднее количество забитых голов гостевой команды в её гостевых матчах \n",
    "    FTG_nearest_diff = sum(Team1_HomeMatch['FTHG'][-10:]*match_significance) - sum(Team2_AwayMatch['FTAG'][-10:]*match_significance)\n",
    "   \n",
    "    FTLG_nearest_diff = sum(Team1_AwayMatch['FTHG'][-10:]*match_significance)-sum(Team2_HomeMatch['FTAG'][-10:]*match_significance) \n",
    "    # разница пропущенных голов домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    S_nearest_diff = sum(Team1_HomeMatch['HS'][-10:]*match_significance)-sum(Team2_AwayMatch['AS'][-10:]*match_significance) \n",
    "    # разница ударов по воротам домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    ST_nearest_diff = sum(Team1_HomeMatch['HST'][-10:]*match_significance) - sum(Team2_AwayMatch['AST'][-10:]*match_significance) \n",
    "    # разница ударов в створ ворот домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "\n",
    "    C_nearest_diff = sum(Team1_HomeMatch['HC'][-10:]*match_significance) -sum(Team2_AwayMatch['AC'][-10:]*match_significance) \n",
    "    # разница угловых домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости   \n",
    "\n",
    "    Team1_HFTR_nearest = sum(Team1_HomeMatch['FTR'][-30:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 домашних матчей \n",
    "    Team2_AFTR_nearest = sum(Team2_AwayMatch['FTR'][-30:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 гостевых матчей\n",
    "                    \n",
    "    Referee_HomeTeam_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[1, 0, 0]).mean() # процент побед домашних команд в последних 10 матчах судьи \n",
    "    Referee_AwayTeam_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[0, 0, 1]).mean() # процент ничейных результатов в последних 10 матчах судьи \n",
    "    Referee_Draw_points = Referee_Match['FTR'][-10:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[0, 1, 0]).mean()     # процент побед гостевых команд в последних 10 матчах судьи \n",
    "    \n",
    "    BK_Teams_diff = max(BK[[\"B365H\", \"BWH\", \"IWH\", \"LBH\", \"WHH\", \"VCH\"]]) - max(BK[[\"B365A\", \"BWA\", \"IWA\", \"LBA\", \"WHA\", \"VCA\"]])\n",
    "    # разница коэффициентов на победу домашней и гостевой команд\n",
    "    BK_Draw = max(BK[[\"B365D\", \"BWD\", \"IWD\", \"LBD\", \"WHD\", \"VCD\"]]) # лучший коэффициент на ничью\n",
    "\n",
    "    return [Team1_FTHG_average, Team2_FTAG_average, FTG_nearest_diff, FTLG_nearest_diff, S_nearest_diff, ST_nearest_diff, \n",
    "            C_nearest_diff, Team1_HFTR_nearest, Team2_AFTR_nearest, Referee_HomeTeam_points, Referee_AwayTeam_points,\n",
    "            Referee_Draw_points, BK_Teams_diff, BK_Draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features3 = [\"Team1_FTHG_average\", \"Team2_FTAG_average\", \"FTG_nearest_diff\", \"FTLG_nearest_diff\", \"S_nearest_diff\", \"ST_nearest_diff\", \n",
    "             \"C_nearest_diff\", \"Team1_HFTR_nearest\", \"Team2_AFTR_nearest\", \"Referee_HomeTeam_points\",\n",
    "             \"Referee_AwayTeam_points\", \"Referee_Draw_points\", \"BK_Teams_diff\", \"BK_Draw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Teams3 = train3['HomeTeam'].append(test3['HomeTeam']).unique() # Список всех команд за 8 лет в 2 английских дивизионах\n",
    "Teams_HomeData3 = {Teams3[i]: start_seasonses3[start_seasonses3[\"HomeTeam\"] == Teams3[i]] for i in range(len(Teams3))} # домашние матчи каждой прогназируемой команды\n",
    "Teams_AwayData3 = {Teams3[i]: start_seasonses3[start_seasonses3[\"AwayTeam\"] == Teams3[i]] for i in range(len(Teams3))} # гостевые матчи каждой прогназируемой команды\n",
    "\n",
    "Referees3 = train3['Referee'].append(test3['Referee']).unique()\n",
    "Referees_Data3 = {Referees3[i]: start_seasonses3[start_seasonses3[\"Referee\"] == Referees3[i]] for i in range(len(Referees3))} # матчи каждого рефери\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X3 = pd.DataFrame(columns = features3)\n",
    "train_Y3 = []\n",
    "test_X3 = pd.DataFrame(columns = features3)\n",
    "test_Y3 = test3[\"FTR\"]\n",
    "\n",
    "# выборка на 7 сезонах для обучения\n",
    "\n",
    "for i in range(len(train3)):\n",
    "    row = train3.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    \n",
    "    if (len(Teams_HomeData3[Team1]) >= 10) & (len(Teams_AwayData3[Team2]) >= 10) & (len(Referees_Data3[Referee]) >= 10):\n",
    "    # если команда только влетела в каком-то сезоне, то на неё нет достаточно информации\n",
    "        BK =  row[attribute_bk]\n",
    "        feature = generate_mix_features(Teams_HomeData3[Team1], Teams_AwayData3[Team1], Teams_HomeData3[Team2], \n",
    "                                        Teams_AwayData3[Team2], Referees_Data3[Referee], BK)\n",
    "        train_X3.loc[i] = feature\n",
    "        train_Y3.append(train3[\"FTR\"].loc[i])\n",
    "        \n",
    "    Teams_HomeData3[Team1] = Teams_HomeData3[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData3[Team2] = Teams_AwayData3[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data3[Referee] = Referees_Data3[Referee].append(row, ignore_index=True)\n",
    "\n",
    "# выборка на 3 неполных сезонах для построения прогнозов\n",
    "\n",
    "for i in range(len(test3)):\n",
    "    row = test3.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    Referee = row[\"Referee\"]\n",
    "    BK =  row[attribute_bk]\n",
    "    \n",
    "    feature = generate_mix_features(Teams_HomeData3[Team1], Teams_AwayData3[Team1], Teams_HomeData3[Team2], \n",
    "                                    Teams_AwayData3[Team2], Referees_Data3[Referee], BK)\n",
    "    test_X3.loc[i] = feature\n",
    "    Teams_HomeData3[Team1] = Teams_HomeData3[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData3[Team2] = Teams_AwayData3[Team2].append(row, ignore_index=True)\n",
    "    Referees_Data3[Referee] = Referees_Data3[Referee].append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.02, loss='deviance',\n",
      "              max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=75, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=0.9, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [2, 3, 4], 'learning_rate': [0.02, 0.03, 0.04],\n",
    "                     'min_samples_leaf':[25, 50, 75], 'n_estimators': [30, 50, 70], \"subsample\": [1, 0.9]}]\n",
    "\n",
    "GB_classifier3 = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier3.fit(train_X3, train_Y3)\n",
    "print(GB_classifier3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X3 = test_X3.replace(to_replace=\"NaN\", value=0) # это не повлияет на результаты, так как в фичах берётся максимум из всех БК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.575038284839\n",
      "На тестовой выборке: 0.538596491228\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>H</th>\n",
       "      <th>prediction</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.299124</td>\n",
       "      <td>0.382069</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.363918</td>\n",
       "      <td>0.303153</td>\n",
       "      <td>0.332928</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.153891</td>\n",
       "      <td>0.225776</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.682404</td>\n",
       "      <td>0.144765</td>\n",
       "      <td>0.172832</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.124126</td>\n",
       "      <td>0.239297</td>\n",
       "      <td>0.636577</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.199224</td>\n",
       "      <td>0.257120</td>\n",
       "      <td>0.543656</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.507147</td>\n",
       "      <td>0.259410</td>\n",
       "      <td>0.233442</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.570107</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>0.202921</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.204749</td>\n",
       "      <td>0.255847</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.256274</td>\n",
       "      <td>0.301876</td>\n",
       "      <td>0.441850</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.285284</td>\n",
       "      <td>0.265127</td>\n",
       "      <td>0.449589</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.126585</td>\n",
       "      <td>0.142947</td>\n",
       "      <td>0.730468</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.194902</td>\n",
       "      <td>0.250227</td>\n",
       "      <td>0.554871</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.290013</td>\n",
       "      <td>0.278013</td>\n",
       "      <td>0.431973</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.130156</td>\n",
       "      <td>0.175513</td>\n",
       "      <td>0.694330</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         D         H prediction result\n",
       "100  0.318807  0.299124  0.382069          H      H\n",
       "101  0.363918  0.303153  0.332928          A      A\n",
       "102  0.153891  0.225776  0.620333          H      H\n",
       "103  0.682404  0.144765  0.172832          A      D\n",
       "104  0.124126  0.239297  0.636577          H      H\n",
       "105  0.199224  0.257120  0.543656          H      D\n",
       "106  0.507147  0.259410  0.233442          A      D\n",
       "107  0.570107  0.226971  0.202921          A      H\n",
       "108  0.204749  0.255847  0.539405          H      A\n",
       "109  0.256274  0.301876  0.441850          H      A\n",
       "110  0.285284  0.265127  0.449589          H      A\n",
       "111  0.126585  0.142947  0.730468          H      H\n",
       "112  0.194902  0.250227  0.554871          H      H\n",
       "113  0.290013  0.278013  0.431973          H      D\n",
       "114  0.130156  0.175513  0.694330          H      H"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_classifier3 = GradientBoostingClassifier(min_samples_split = 2, max_depth = 4, learning_rate = 0.03, min_samples_leaf = 50,\n",
    "                                            subsample = 0.9, n_estimators = 50, random_state = 42)\n",
    "GB_classifier3.fit(train_X3, train_Y3)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y3, GB_classifier3.predict(train_X3))))\n",
    "\n",
    "proba_GB3 = GB_classifier3.predict_proba(test_X3)\n",
    "prediction_GB3 = GB_classifier3.predict(test_X3)\n",
    "\n",
    "result_GB3 = pd.DataFrame()\n",
    "result_GB3[0] = proba_GB3[:,0]\n",
    "result_GB3[1] = proba_GB3[:,1]\n",
    "result_GB3[2] = proba_GB3[:,2]\n",
    "result_GB3[3] = prediction_GB3\n",
    "result_GB3[4] = test_Y3\n",
    "\n",
    "result_GB3.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB3 = accuracy_score(test_Y3, result_GB3[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB3))\n",
    "\n",
    "result_GB3[100:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>FTG_nearest_diff</th>\n",
       "      <th>FTLG_nearest_diff</th>\n",
       "      <th>S_nearest_diff</th>\n",
       "      <th>ST_nearest_diff</th>\n",
       "      <th>C_nearest_diff</th>\n",
       "      <th>Team1_HFTR_nearest</th>\n",
       "      <th>Team2_AFTR_nearest</th>\n",
       "      <th>Referee_HomeTeam_points</th>\n",
       "      <th>Referee_AwayTeam_points</th>\n",
       "      <th>Referee_Draw_points</th>\n",
       "      <th>BK_Teams_diff</th>\n",
       "      <th>BK_Draw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.07411</td>\n",
       "      <td>0.061163</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>0.051685</td>\n",
       "      <td>0.063498</td>\n",
       "      <td>0.101564</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.01207</td>\n",
       "      <td>0.406308</td>\n",
       "      <td>0.07167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1_FTHG_average  Team2_FTAG_average  FTG_nearest_diff  \\\n",
       "0             0.07411            0.061163          0.027631   \n",
       "\n",
       "   FTLG_nearest_diff  S_nearest_diff  ST_nearest_diff  C_nearest_diff  \\\n",
       "0           0.051685        0.063498         0.101564        0.046001   \n",
       "\n",
       "   Team1_HFTR_nearest  Team2_AFTR_nearest  Referee_HomeTeam_points  \\\n",
       "0            0.034113            0.014436                 0.015487   \n",
       "\n",
       "   Referee_AwayTeam_points  Referee_Draw_points  BK_Teams_diff  BK_Draw  \n",
       "0                 0.020264              0.01207       0.406308  0.07167  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([GB_classifier3.feature_importances_], columns = train_X3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40% зависит от катировок букмекеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H    796\n",
       "A    335\n",
       "D      9\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_GB3[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175,   5, 160],\n",
       "       [ 77,   1, 206],\n",
       "       [ 83,   3, 430]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_Y3, result_GB3[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чуть больше половины мы угадываем, примерно в 24% случаях наши результаты уходят на каждый из оставшихся исходов. Ничьи никак не получается прогнозировать. Поэтому попробуем сделать допущение - \"Если модель выдаёт близкие вероятности на победы одной и второй команды, то говорим что они сыграют в ничью\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До: 0.56010719755\n",
      "После: 0.560872894334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 355,   38,  342],\n",
       "       [ 155,   52,  458],\n",
       "       [ 113,   41, 1058]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"До: \" + str(accuracy_score(train_Y3, GB_classifier3.predict(train_X3))))\n",
    "\n",
    "proba_GB3_fix = GB_classifier3.predict_proba(train_X3)\n",
    "prediction_GB3_fix = GB_classifier3.predict(train_X3)\n",
    "\n",
    "result_GB3_fix = pd.DataFrame()\n",
    "result_GB3_fix[0] = proba_GB3_fix[:,0]\n",
    "result_GB3_fix[1] = proba_GB3_fix[:,1]\n",
    "result_GB3_fix[2] = proba_GB3_fix[:,2]\n",
    "\n",
    "# Если команды почти равны по силе, то ставим на ничью\n",
    "for i in range(len(result_GB3_fix)):\n",
    "    if abs(result_GB3_fix.ix[i][0]-result_GB3_fix.ix[i][2]) < 0.03:\n",
    "        prediction_GB3_fix[i] = \"D\"\n",
    "\n",
    "result_GB3_fix[3] = prediction_GB3_fix\n",
    "result_GB3_fix[4] = train_Y3\n",
    "\n",
    "result_GB3_fix.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "print(\"После: \" + str(accuracy_score(result_GB3_fix[\"prediction\"], result_GB3_fix[\"result\"])))\n",
    "confusion_matrix(train_Y3, result_GB3_fix[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С одной стороны процент правильно спрогнозированных матчей вырос. Но с другой стороны [32, 38, 37] говорит о том что ставя в таких случаях на ничью процент правильных прогнозов становититься равным 52/(38+52+41) или примерно 40%. Но, увеличивая порог для ничейных результатов, получаем результаты ничьих сходящиеся к 33.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На первом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "GB_classifier = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "GB_classifier.fit(train_X, train_Y)\n",
    "print(GB_classifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке со статистическими данными: 0.456581183948\n",
      "На тестовой выборке со статистическими данными: 0.514912280702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[189,   1, 150],\n",
       "       [ 98,   0, 186],\n",
       "       [118,   0, 398]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Логистическая регрессия на статистических данных\n",
    "\n",
    "LR_classifier = LogisticRegression(random_state = 42, C=0.4, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "LR_classifier.fit(train_X, train_Y)\n",
    "\n",
    "print(\"На тренировочной выборке со статистическими данными: \" + str(accuracy_score(train_Y, LR_classifier.predict(train_X))))\n",
    "\n",
    "proba_LR = LR_classifier.predict_proba(test_X)\n",
    "prediction_LR = LR_classifier.predict(test_X)\n",
    "\n",
    "result_LR = pd.DataFrame()\n",
    "result_LR[0] = proba_LR[:,0]\n",
    "result_LR[1] = proba_LR[:,1]\n",
    "result_LR[2] = proba_LR[:,2]\n",
    "result_LR[3] = prediction_LR\n",
    "result_LR[4] = test_Y\n",
    "\n",
    "result_LR.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "\n",
    "score_LR = accuracy_score(test_Y, result_LR[\"prediction\"])\n",
    "print(\"На тестовой выборке со статистическими данными: \" + str(score_LR))\n",
    "\n",
    "confusion_matrix(test_Y, result_LR[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До: 0.514912280702\n",
      "После: 0.514912280702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[173,  32, 135],\n",
       "       [ 79,  37, 168],\n",
       "       [ 98,  41, 377]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"До: \" + str(accuracy_score(test_Y, result_LR[\"prediction\"])))\n",
    "proba_LR_fix = LR_classifier.predict_proba(test_X)\n",
    "prediction_LR_fix = LR_classifier.predict(test_X)\n",
    "\n",
    "result_LR_fix = pd.DataFrame()\n",
    "result_LR_fix[0] = proba_LR_fix[:,0]\n",
    "result_LR_fix[1] = proba_LR_fix[:,1]\n",
    "result_LR_fix[2] = proba_LR_fix[:,2]\n",
    "\n",
    "# Если команды почти равны по силе, то ставим на ничью\n",
    "for i in range(len(result_LR_fix)):\n",
    "    if abs(result_LR_fix.ix[i][0]-result_LR_fix.ix[i][2]) < 0.03:\n",
    "        prediction_LR_fix[i] = \"D\"\n",
    "        \n",
    "result_LR_fix[3] = prediction_LR_fix\n",
    "result_LR_fix[4] = test_Y\n",
    "\n",
    "result_LR_fix.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR_fix = accuracy_score(test_Y, result_LR_fix[\"prediction\"])\n",
    "print(\"После: \" + str(score_LR_fix))\n",
    "\n",
    "confusion_matrix(test_Y, result_LR_fix[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На втором наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "LR_classifier2 = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "LR_classifier2.fit(train_X2, train_Y2)\n",
    "print(LR_classifier2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До: 0.521929824561\n",
      "После: 0.531578947368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[180,  18, 142],\n",
       "       [ 89,  28, 167],\n",
       "       [105,  13, 398]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"До: \" + str(accuracy_score(test_Y2, result_LR2[\"prediction\"])))\n",
    "proba_LR2_fix = LR_classifier2.predict_proba(test_X2)\n",
    "prediction_LR2_fix = LR_classifier2.predict(test_X2)\n",
    "\n",
    "result_LR2_fix = pd.DataFrame()\n",
    "result_LR2_fix[0] = proba_LR2_fix[:,0]\n",
    "result_LR2_fix[1] = proba_LR2_fix[:,1]\n",
    "result_LR2_fix[2] = proba_LR2_fix[:,2]\n",
    "\n",
    "# Если команды почти равны по силе, то ставим на ничью\n",
    "for i in range(len(result_LR2_fix)):\n",
    "    if abs(result_LR2_fix.ix[i][0]-result_LR2_fix.ix[i][2]) < 0.03:\n",
    "        prediction_LR2_fix[i] = \"D\"\n",
    "        \n",
    "result_LR2_fix[3] = prediction_LR2_fix\n",
    "result_LR2_fix[4] = test_Y2\n",
    "\n",
    "result_LR2_fix.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR2_fix = accuracy_score(test_Y2, result_LR2_fix[\"prediction\"])\n",
    "print(\"После: \" + str(score_LR2_fix))\n",
    "\n",
    "confusion_matrix(test_Y2, result_LR2_fix[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке со статистическими данными: 0.528713629403\n",
      "На тестовой выборке со статистическими данными: 0.521929824561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[189,   1, 150],\n",
       "       [100,   2, 182],\n",
       "       [110,   2, 404]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier2 = LogisticRegression(random_state = 42, C=1.5, tol=0.0001, max_iter=50, solver='liblinear')\n",
    "LR_classifier2.fit(train_X2, train_Y2)\n",
    "\n",
    "print(\"На тренировочной выборке со статистическими данными: \" + str(accuracy_score(train_Y2, LR_classifier2.predict(train_X2))))\n",
    "\n",
    "proba_LR2 = LR_classifier2.predict_proba(test_X2)\n",
    "prediction_LR2 = LR_classifier2.predict(test_X2)\n",
    "\n",
    "result_LR2 = pd.DataFrame()\n",
    "result_LR2[0] = proba_LR2[:,0]\n",
    "result_LR2[1] = proba_LR2[:,1]\n",
    "result_LR2[2] = proba_LR2[:,2]\n",
    "result_LR2[3] = prediction_LR2\n",
    "result_LR2[4] = test_Y2\n",
    "\n",
    "result_LR2.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR2 = accuracy_score(test_Y2, result_LR2[\"prediction\"])\n",
    "print(\"На тестовой выборке со статистическими данными: \" + str(score_LR2))\n",
    "\n",
    "confusion_matrix(test_Y2, result_LR2[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На третьем наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "LR_classifier3 = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "LR_classifier3.fit(train_X3, train_Y3)\n",
    "print(LR_classifier3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке со статистическими данными: 0.545941807044\n",
      "На тестовой выборке со статистическими данными: 0.535087719298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[175,   4, 161],\n",
       "       [ 79,   4, 201],\n",
       "       [ 82,   3, 431]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier3 = LogisticRegression(random_state = 42, C=0.4, tol=0.0001, max_iter=50, solver='liblinear')\n",
    "LR_classifier3.fit(train_X3, train_Y3)\n",
    "\n",
    "print(\"На тренировочной выборке со статистическими данными: \" + str(accuracy_score(train_Y3, LR_classifier3.predict(train_X3))))\n",
    "\n",
    "proba_LR3 = LR_classifier3.predict_proba(test_X3)\n",
    "prediction_LR3 = LR_classifier3.predict(test_X3)\n",
    "\n",
    "result_LR3 = pd.DataFrame()\n",
    "result_LR3[0] = proba_LR3[:,0]\n",
    "result_LR3[1] = proba_LR3[:,1]\n",
    "result_LR3[2] = proba_LR3[:,2]\n",
    "result_LR3[3] = prediction_LR3\n",
    "result_LR3[4] = test_Y3\n",
    "\n",
    "result_LR3.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR3 = accuracy_score(test_Y3, result_LR3[\"prediction\"])\n",
    "print(\"На тестовой выборке со статистическими данными: \" + str(score_LR3))\n",
    "\n",
    "confusion_matrix(test_Y3, result_LR3[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До: 0.535087719298\n",
      "После: 0.535964912281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[171,  18, 151],\n",
       "       [ 74,  18, 192],\n",
       "       [ 77,  17, 422]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"До: \" + str(accuracy_score(test_Y3, result_LR3[\"prediction\"])))\n",
    "proba_LR3_fix = LR_classifier3.predict_proba(test_X3)\n",
    "prediction_LR3_fix = LR_classifier3.predict(test_X3)\n",
    "\n",
    "result_LR3_fix = pd.DataFrame()\n",
    "result_LR3_fix[0] = proba_LR3_fix[:,0]\n",
    "result_LR3_fix[1] = proba_LR3_fix[:,1]\n",
    "result_LR3_fix[2] = proba_LR3_fix[:,2]\n",
    "\n",
    "# Если команды почти равны по силе, то ставим на ничью\n",
    "for i in range(len(result_LR3_fix)):\n",
    "    if abs(result_LR3_fix.ix[i][0]-result_LR3_fix.ix[i][2]) < 0.02:\n",
    "        prediction_LR3_fix[i] = \"D\"\n",
    "        \n",
    "result_LR3_fix[3] = prediction_LR3_fix\n",
    "result_LR3_fix[4] = test_Y3\n",
    "\n",
    "result_LR3_fix.columns = [\"A\", \"D\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR3_fix = accuracy_score(test_Y3, result_LR3_fix[\"prediction\"])\n",
    "print(\"После: \" + str(score_LR3_fix))\n",
    "\n",
    "confusion_matrix(test_Y3, result_LR3_fix[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Промежуточные результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как понять, насколько хороши эти прогнозы? Для этого посмотрим чтобы было, если бы мы всегда ставили на фаворитов по букмекерским коэффициентам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534210526316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[175,  18, 147],\n",
       "       [ 76,  14, 194],\n",
       "       [ 82,  14, 420]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite=[]\n",
    "BK_Team1 = test[\"IWH\"]\n",
    "BK_Team2 = test[\"IWA\"]\n",
    "\n",
    "for i in range(len(BK_Team1)):\n",
    "    if BK_Team1.loc[i] - BK_Team2.loc[i] < 0:\n",
    "        favorite.append(\"H\")\n",
    "    elif BK_Team1.loc[i] - BK_Team2.loc[i] > 0:\n",
    "        favorite.append(\"A\")\n",
    "    else:\n",
    "        favorite.append(\"D\")\n",
    "\n",
    "score_favorite = accuracy_score(favorite, test_Y)\n",
    "print(score_favorite)\n",
    "\n",
    "confusion_matrix(test_Y, favorite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716121495327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[189,  92],\n",
       "       [151, 424]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite2=[]\n",
    "BK_Team1 = test2_HA[\"B365H\"]\n",
    "BK_Team2 = test2_HA[\"B365A\"]\n",
    "\n",
    "for i in range(len(BK_Team1)):\n",
    "    if BK_Team1.loc[i] - BK_Team2.loc[i] < 0:\n",
    "        favorite2.append(\"H\")\n",
    "    else:\n",
    "        favorite2.append(\"A\")\n",
    "\n",
    "        \n",
    "print(accuracy_score(favorite2, test_Y2_HA))\n",
    "\n",
    "confusion_matrix(favorite2, test_Y2_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'A']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели построеные только на статистических данных, имеет чуть меньший результат угадываний, чем способ ставить всё время на фаворитов. Модели построенная на БК коэффициентах с добавление шума, в виде статистических данных и поднятием ничейных исходов, имеет схожий процент верно угаданных исходов. Однако, этот шум может отклонить результаты и в любую сторону. Раз такая беда с ничьими, порбоуем немного другую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Победа гостевой или домашней команды. HA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как модель ни в какую не прогнозирует ничьи, то поступим так. Попробуем прогнозировать только победу домашней и гостевой команд. В таких случаях в БК существует отдельное событие \"Результат, не включая ничью\". Раньше было 3 исхода и 3 коэффициента на них, теперь остаётся теже 3 исхода, но 2 коэффициента (на победу гостевой и домашней команд). В случаи ничьи деньги возвращаются обратно. Классификаторы будут теже, изменяться только вероятности на исходы. Их изначально нету, но если ввести предположение, что маржа букмекера на эти события одинакова, то из первых вероятностей можно получить вторые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformate_coef(H_coef, D_coef, A_coef):\n",
    "    H_prob = 1/H_coef\n",
    "    D_prob = 1/D_coef\n",
    "    A_prob = 1/A_coef\n",
    "    margin = (H_prob + D_prob + A_prob)\n",
    "    H_prob_new = margin * H_prob/(H_prob + A_prob)\n",
    "    A_prob_new = margin * A_prob/(H_prob + A_prob)\n",
    "    \n",
    "    return [1/H_prob_new, 1, 1/A_prob_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обычные коэффициенты: [1.25, 6.5, 15.0];\n",
      "Маржа букмекера: 2.0513%;\n",
      "0.8 0.0666666666667 0.153846153846\n",
      "0.855913978495 0.164598842018\n",
      "Новые коэффициенты: [1.1683, 6.0754];\n",
      "Новая маржа: 2.0513%;\n"
     ]
    }
   ],
   "source": [
    "T1 = test.ix[0][\"B365H\"]\n",
    "T2 = test.ix[0][\"B365A\"]\n",
    "TX = test.ix[0][\"B365D\"]\n",
    "M = round(((1/T1 + 1/T2 + 1/TX)-1)*100, 4)\n",
    "\n",
    "print(\"Обычные коэффициенты: \" + \"[\" + str(T1) + \", \" + str(TX) + \", \" + str(T2) + \"];\")\n",
    "print(\"Маржа букмекера: \" + str(M) + \"%;\")\n",
    "[T1_new, TX_new, T2_new] = reformate_coef(T1, T2, TX)\n",
    "M_new = round(((1/T1_new + 1/T2_new)-1)*100,4) \n",
    "      \n",
    "print(\"Новые коэффициенты: \" + \"[\" + str(round(T1_new, 4)) + \", \" + str(round(T2_new, 4)) + \"];\")\n",
    "print(\"Новая маржа: \" + str(M) + \"%;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# переформировываем обучающую выборку, убирая от туда ничейные результаты.\n",
    "\n",
    "def reformate_data(X, Y):\n",
    "    data = X\n",
    "    data[\"result\"] = Y\n",
    "    data = data[(data[\"result\"]==\"A\") | (data[\"result\"]==\"H\")]\n",
    "    data.index = [x for x in range(len(data))] # перебивка индексов\n",
    "\n",
    "    Y_new = data[\"result\"]\n",
    "    X_new = data\n",
    "    del X_new[\"result\"]\n",
    "    \n",
    "    return [X_new, Y_new]\n",
    "\n",
    "[train_X2_HA, train_Y2_HA] = reformate_data(train_X2, train_Y2)\n",
    "[train_X3_HA, train_Y3_HA] = reformate_data(train_X3, train_Y3)\n",
    "\n",
    "# Так как в тестовой выборке при ничейном исходе нам просто вернут деньги, то эти случаи можно не учитывать в прогнозе\n",
    "[test_X2_HA, test_Y2_HA] = reformate_data(test_X2, test_Y2)\n",
    "[test_X3_HA, test_Y3_HA] = reformate_data(test_X3, test_Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогноз HA, на данных со вторым набором фич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый набор данных показал плохие прогнозы, как в логистической регрессии, так и в градиентном бустинге. Поэтому Прогнозы на новое событие строим по 2 наборам данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.04, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=30, min_samples_split=1,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "              presort='auto', random_state=None, subsample=1, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [3, 4], 'learning_rate': [0.03, 0.04],\n",
    "                     'min_samples_leaf':[30, 50, 70], 'n_estimators': [30, 50, 70], \"subsample\": [1, 0.9]}]\n",
    "\n",
    "GB_classifier2_HA = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier2_HA.fit(train_X2_HA, train_Y2_HA)\n",
    "print(GB_classifier2_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.744221879815\n",
      "На тестовой выборке: 0.704439252336\n",
      "[[170 170]\n",
      " [ 83 433]]\n"
     ]
    }
   ],
   "source": [
    "GB_classifier2_HA = GradientBoostingClassifier(min_samples_split = 2, max_depth = 4, learning_rate = 0.03, \n",
    "                                               min_samples_leaf = 50, n_estimators = 70, subsample=0.9, random_state=42)\n",
    "GB_classifier2_HA.fit(train_X2_HA, train_Y2_HA)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y2_HA, GB_classifier2_HA.predict(train_X2_HA))))\n",
    "\n",
    "proba_GB2_HA = GB_classifier2_HA.predict_proba(test_X2_HA)\n",
    "prediction_GB2_HA = GB_classifier2_HA.predict(test_X2_HA)\n",
    "\n",
    "result_GB2_HA = pd.DataFrame()\n",
    "result_GB2_HA[0] = proba_GB2_HA[:,0]\n",
    "result_GB2_HA[1] = proba_GB2_HA[:,1]\n",
    "result_GB2_HA[2] = prediction_GB2_HA\n",
    "result_GB2_HA[3] = test_Y2_HA\n",
    "\n",
    "result_GB2_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB2_HA = accuracy_score(test_Y2_HA, result_GB2_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB2_HA))\n",
    "\n",
    "print(confusion_matrix(result_GB2_HA[\"result\"], result_GB2_HA[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.6, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "LR_classifier2_HA = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "LR_classifier2_HA.fit(train_X2_HA, train_Y2_HA)\n",
    "print(LR_classifier2_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборкe: 0.713405238829\n",
      "На тестовой выборке: 0.69976635514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[191, 149],\n",
       "       [108, 408]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier2_HA = LogisticRegression(random_state = 42, C=0.8, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "LR_classifier2_HA.fit(train_X2_HA, train_Y2_HA)\n",
    "\n",
    "print(\"На тренировочной выборкe: \" + str(accuracy_score(train_Y2_HA, LR_classifier2_HA.predict(train_X2_HA))))\n",
    "\n",
    "proba_LR2_HA = LR_classifier2_HA.predict_proba(test_X2_HA)\n",
    "prediction_LR2_HA = LR_classifier2_HA.predict(test_X2_HA)\n",
    "\n",
    "result_LR2_HA = pd.DataFrame()\n",
    "result_LR2_HA[0] = proba_LR2_HA[:,0]\n",
    "result_LR2_HA[1] = proba_LR2_HA[:,1]\n",
    "result_LR2_HA[2] = prediction_LR2_HA\n",
    "result_LR2_HA[3] = test_Y2_HA\n",
    "\n",
    "result_LR2_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR2_HA = accuracy_score(test_Y2_HA, result_LR2_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_LR2_HA))\n",
    "\n",
    "confusion_matrix(test_Y2_HA, result_LR2_HA[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По двум исходам прогноз, даже на статистических данных, заметно вырос. Попробуем построить на третьем наборе фич."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогноз HA, на данных с третьим набором фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.04, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=70, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "              presort='auto', random_state=None, subsample=0.9, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [2, 3, 4], 'learning_rate': [0.03, 0.04],\n",
    "                     'min_samples_leaf':[30, 50, 70], 'n_estimators': [30, 50, 70, 90], \"subsample\": [1, 0.9]}]\n",
    "\n",
    "GB_classifier3_HA = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier3_HA.fit(train_X3_HA, train_Y3_HA)\n",
    "print(GB_classifier3_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.752439650745\n",
      "На тестовой выборке: 0.716121495327\n",
      "[[185 155]\n",
      " [ 88 428]]\n"
     ]
    }
   ],
   "source": [
    "GB_classifier3_HA = GradientBoostingClassifier(min_samples_split = 1, max_depth = 3, learning_rate = 0.04, \n",
    "                                               min_samples_leaf = 30, n_estimators = 50, subsample=0.9, random_state=42)\n",
    "GB_classifier3_HA.fit(train_X3_HA, train_Y3_HA)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y3_HA, GB_classifier3_HA.predict(train_X3_HA))))\n",
    "\n",
    "proba_GB3_HA = GB_classifier3_HA.predict_proba(test_X3_HA)\n",
    "prediction_GB3_HA = GB_classifier3_HA.predict(test_X3_HA)\n",
    "\n",
    "result_GB3_HA = pd.DataFrame()\n",
    "result_GB3_HA[0] = proba_GB3_HA[:,0]\n",
    "result_GB3_HA[1] = proba_GB3_HA[:,1]\n",
    "result_GB3_HA[2] = prediction_GB3_HA\n",
    "result_GB3_HA[3] = test_Y3_HA\n",
    "\n",
    "result_GB3_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB3_HA = accuracy_score(test_Y3_HA, result_GB3_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB3_HA))\n",
    "\n",
    "print(confusion_matrix(result_GB3_HA[\"result\"], result_GB3_HA[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "LR_classifier3_HA = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "LR_classifier3_HA.fit(train_X3_HA, train_Y3_HA)\n",
    "print(LR_classifier3_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.735490498202\n",
      "На тестовой выборке: 0.709112149533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168, 172],\n",
       "       [ 77, 439]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier3_HA = LogisticRegression(random_state = 42, C=0.6, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "LR_classifier3_HA.fit(train_X3_HA, train_Y3_HA)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y3_HA, LR_classifier3_HA.predict(train_X3_HA))))\n",
    "\n",
    "proba_LR3_HA = LR_classifier3_HA.predict_proba(test_X3_HA)\n",
    "prediction_LR3_HA = LR_classifier3_HA.predict(test_X3_HA)\n",
    "\n",
    "result_LR3_HA = pd.DataFrame()\n",
    "result_LR3_HA[0] = proba_LR3_HA[:,0]\n",
    "result_LR3_HA[1] = proba_LR3_HA[:,1]\n",
    "result_LR3_HA[2] = prediction_LR3_HA\n",
    "result_LR3_HA[3] = test_Y3_HA\n",
    "\n",
    "result_LR3_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR3_HA = accuracy_score(test_Y3_HA, result_LR3_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_LR3_HA))\n",
    "\n",
    "confusion_matrix(test_Y3_HA, result_LR3_HA[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# А что если делать ставки на эти прогнозы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь спрогнозируем ситуацию - имеется 100 у.е. и мы ставим на матчи, учитывая результаты нашей модели. Посмотрим к чему это приведёт. Начнём с элементарного, на каждый матч ставим 1 у.е. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(test)==len(test_X), len(test2)==len(test_X2), len(test3)==len(test_X3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала предположим что у нас есть аккаунт только в одной БК."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_prediction(data, prediction, result, rate):\n",
    "    BK_coef = data[[\"B365A\", \"B365D\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"D\", \"H\"]\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        cash = cash - rate\n",
    "        if result[i]==prediction[i]:\n",
    "            cash = cash + rate*BK_coef[result[i]].loc[i]\n",
    "        cash_history.append(cash)\n",
    "            \n",
    "    return cash_history\n",
    "\n",
    "def test_prediction_HA(data, prediction, result, rate):\n",
    "    BK_coef = data[[\"B365A\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"H\"]\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        cash = cash - rate\n",
    "        if result[i]==prediction[i]:\n",
    "            cash = cash + rate*BK_coef[result[i]].loc[i]\n",
    "        cash_history.append(cash)\n",
    "            \n",
    "    return cash_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Result = pd.DataFrame()\n",
    "Result[\"favorite\"] = test_prediction(test, favorite, test_Y, 1)\n",
    "Result[\"Cash_GB\"] = test_prediction(test, prediction_GB, test_Y, 1)\n",
    "Result[\"Cash_GB2\"] = test_prediction(test2, prediction_GB2, test_Y2, 1)\n",
    "Result[\"Cash_GB3\"] = test_prediction(test3, prediction_GB3, test_Y3, 1)\n",
    "Result[\"Cash_LR\"] = test_prediction(test, prediction_LR, test_Y, 1)\n",
    "Result[\"Cash_LR_fix\"] = test_prediction(test, prediction_LR_fix, test_Y, 1)\n",
    "Result[\"Cash_LR2\"] = test_prediction(test2, prediction_LR2, test_Y2, 1)\n",
    "Result[\"Cash_LR2_fix\"] = test_prediction(test2, prediction_LR2_fix, test_Y2, 1)\n",
    "Result[\"Cash_LR3\"] = test_prediction(test3, prediction_LR3, test_Y3, 1)\n",
    "Result[\"Cash_LR3_fix\"] = test_prediction(test3, prediction_LR3_fix, test_Y3, 1)\n",
    "\n",
    "# события с двумя исходами\n",
    "test2_HA = test2[(test2[\"FTR\"]==\"A\") | (test2[\"FTR\"]==\"H\")][[\"B365H\", \"B365D\", \"B365A\"]]\n",
    "test2_HA.index = [x for x in range(len(test2_HA))]\n",
    "for i in range(len(test2_HA)):\n",
    "    row = test2_HA.loc[i]\n",
    "    test2_HA.loc[i] = reformate_coef(row[\"B365H\"], row[\"B365D\"], row[\"B365A\"]) \n",
    "test3_HA = test3[(test3[\"FTR\"]==\"A\") | (test3[\"FTR\"]==\"H\")][[\"B365H\", \"B365D\", \"B365A\"]]\n",
    "test3_HA.index = [x for x in range(len(test3_HA))]\n",
    "for i in range(len(test3_HA)):\n",
    "    row = test3_HA.loc[i]\n",
    "    test3_HA.loc[i] = reformate_coef(row[\"B365H\"], row[\"B365D\"], row[\"B365A\"]) \n",
    "\n",
    "Result_HA = pd.DataFrame()\n",
    "Result_HA[\"Cash_GB2_HA\"] = test_prediction_HA(test2_HA, prediction_GB2_HA, test_Y2_HA, 1)\n",
    "Result_HA[\"Cash_GB3_HA\"] = test_prediction_HA(test3_HA, prediction_GB3_HA, test_Y3_HA, 1)\n",
    "Result_HA[\"Cash_LR2_HA\"] = test_prediction_HA(test2_HA, prediction_LR2_HA, test_Y2_HA, 1)\n",
    "Result_HA[\"Cash_LR3_HA\"] = test_prediction_HA(test3_HA, prediction_LR3_HA, test_Y3_HA, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cash_GB2_HA</th>\n",
       "      <th>Cash_GB3_HA</th>\n",
       "      <th>Cash_LR2_HA</th>\n",
       "      <th>Cash_LR3_HA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>89.962486</td>\n",
       "      <td>79.558514</td>\n",
       "      <td>76.084703</td>\n",
       "      <td>70.041103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>90.129003</td>\n",
       "      <td>79.725031</td>\n",
       "      <td>76.251220</td>\n",
       "      <td>70.207620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>89.129003</td>\n",
       "      <td>78.725031</td>\n",
       "      <td>75.251220</td>\n",
       "      <td>69.207620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>89.146238</td>\n",
       "      <td>78.742266</td>\n",
       "      <td>75.268455</td>\n",
       "      <td>69.224855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>89.336656</td>\n",
       "      <td>78.932683</td>\n",
       "      <td>75.458873</td>\n",
       "      <td>69.415272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>89.353891</td>\n",
       "      <td>78.949918</td>\n",
       "      <td>75.476108</td>\n",
       "      <td>69.432507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>90.115233</td>\n",
       "      <td>79.711260</td>\n",
       "      <td>76.237450</td>\n",
       "      <td>70.193849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>89.115233</td>\n",
       "      <td>78.711260</td>\n",
       "      <td>75.237450</td>\n",
       "      <td>69.193849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>89.631899</td>\n",
       "      <td>79.227927</td>\n",
       "      <td>75.754116</td>\n",
       "      <td>69.710516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>89.720889</td>\n",
       "      <td>79.316917</td>\n",
       "      <td>75.843106</td>\n",
       "      <td>69.799506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
       "846    89.962486    79.558514    76.084703    70.041103\n",
       "847    90.129003    79.725031    76.251220    70.207620\n",
       "848    89.129003    78.725031    75.251220    69.207620\n",
       "849    89.146238    78.742266    75.268455    69.224855\n",
       "850    89.336656    78.932683    75.458873    69.415272\n",
       "851    89.353891    78.949918    75.476108    69.432507\n",
       "852    90.115233    79.711260    76.237450    70.193849\n",
       "853    89.115233    78.711260    75.237450    69.193849\n",
       "854    89.631899    79.227927    75.754116    69.710516\n",
       "855    89.720889    79.316917    75.843106    69.799506"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_HA[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite</th>\n",
       "      <th>Cash_GB</th>\n",
       "      <th>Cash_GB2</th>\n",
       "      <th>Cash_GB3</th>\n",
       "      <th>Cash_LR</th>\n",
       "      <th>Cash_LR_fix</th>\n",
       "      <th>Cash_LR2</th>\n",
       "      <th>Cash_LR2_fix</th>\n",
       "      <th>Cash_LR3</th>\n",
       "      <th>Cash_LR3_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>73.74</td>\n",
       "      <td>89.32</td>\n",
       "      <td>91.64</td>\n",
       "      <td>57.09</td>\n",
       "      <td>39.41</td>\n",
       "      <td>88.77</td>\n",
       "      <td>74.38</td>\n",
       "      <td>75.83</td>\n",
       "      <td>57.13</td>\n",
       "      <td>79.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>72.74</td>\n",
       "      <td>88.32</td>\n",
       "      <td>90.64</td>\n",
       "      <td>56.09</td>\n",
       "      <td>38.41</td>\n",
       "      <td>87.77</td>\n",
       "      <td>73.38</td>\n",
       "      <td>74.83</td>\n",
       "      <td>56.13</td>\n",
       "      <td>78.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>72.88</td>\n",
       "      <td>88.46</td>\n",
       "      <td>90.78</td>\n",
       "      <td>56.23</td>\n",
       "      <td>38.55</td>\n",
       "      <td>87.91</td>\n",
       "      <td>73.52</td>\n",
       "      <td>74.97</td>\n",
       "      <td>56.27</td>\n",
       "      <td>78.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>73.38</td>\n",
       "      <td>88.96</td>\n",
       "      <td>91.28</td>\n",
       "      <td>56.73</td>\n",
       "      <td>39.05</td>\n",
       "      <td>88.41</td>\n",
       "      <td>74.02</td>\n",
       "      <td>75.47</td>\n",
       "      <td>56.77</td>\n",
       "      <td>79.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>72.38</td>\n",
       "      <td>87.96</td>\n",
       "      <td>90.28</td>\n",
       "      <td>55.73</td>\n",
       "      <td>38.05</td>\n",
       "      <td>87.41</td>\n",
       "      <td>73.02</td>\n",
       "      <td>74.47</td>\n",
       "      <td>55.77</td>\n",
       "      <td>78.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>72.52</td>\n",
       "      <td>88.10</td>\n",
       "      <td>90.42</td>\n",
       "      <td>55.87</td>\n",
       "      <td>38.19</td>\n",
       "      <td>87.55</td>\n",
       "      <td>73.16</td>\n",
       "      <td>74.61</td>\n",
       "      <td>55.91</td>\n",
       "      <td>78.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>74.02</td>\n",
       "      <td>89.60</td>\n",
       "      <td>91.92</td>\n",
       "      <td>57.37</td>\n",
       "      <td>39.69</td>\n",
       "      <td>89.05</td>\n",
       "      <td>74.66</td>\n",
       "      <td>76.11</td>\n",
       "      <td>57.41</td>\n",
       "      <td>79.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>73.02</td>\n",
       "      <td>88.60</td>\n",
       "      <td>90.92</td>\n",
       "      <td>56.37</td>\n",
       "      <td>38.69</td>\n",
       "      <td>88.05</td>\n",
       "      <td>73.66</td>\n",
       "      <td>75.11</td>\n",
       "      <td>56.41</td>\n",
       "      <td>78.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>74.12</td>\n",
       "      <td>89.70</td>\n",
       "      <td>92.02</td>\n",
       "      <td>57.47</td>\n",
       "      <td>39.79</td>\n",
       "      <td>89.15</td>\n",
       "      <td>74.76</td>\n",
       "      <td>76.21</td>\n",
       "      <td>57.51</td>\n",
       "      <td>79.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>74.42</td>\n",
       "      <td>90.00</td>\n",
       "      <td>92.32</td>\n",
       "      <td>57.77</td>\n",
       "      <td>40.09</td>\n",
       "      <td>89.45</td>\n",
       "      <td>75.06</td>\n",
       "      <td>76.51</td>\n",
       "      <td>57.81</td>\n",
       "      <td>80.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      favorite  Cash_GB  Cash_GB2  Cash_GB3  Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
       "1130     73.74    89.32     91.64     57.09    39.41        88.77     74.38   \n",
       "1131     72.74    88.32     90.64     56.09    38.41        87.77     73.38   \n",
       "1132     72.88    88.46     90.78     56.23    38.55        87.91     73.52   \n",
       "1133     73.38    88.96     91.28     56.73    39.05        88.41     74.02   \n",
       "1134     72.38    87.96     90.28     55.73    38.05        87.41     73.02   \n",
       "1135     72.52    88.10     90.42     55.87    38.19        87.55     73.16   \n",
       "1136     74.02    89.60     91.92     57.37    39.69        89.05     74.66   \n",
       "1137     73.02    88.60     90.92     56.37    38.69        88.05     73.66   \n",
       "1138     74.12    89.70     92.02     57.47    39.79        89.15     74.76   \n",
       "1139     74.42    90.00     92.32     57.77    40.09        89.45     75.06   \n",
       "\n",
       "      Cash_LR2_fix  Cash_LR3  Cash_LR3_fix  \n",
       "1130         75.83     57.13         79.60  \n",
       "1131         74.83     56.13         78.60  \n",
       "1132         74.97     56.27         78.74  \n",
       "1133         75.47     56.77         79.24  \n",
       "1134         74.47     55.77         78.24  \n",
       "1135         74.61     55.91         78.38  \n",
       "1136         76.11     57.41         79.88  \n",
       "1137         75.11     56.41         78.88  \n",
       "1138         76.21     57.51         79.98  \n",
       "1139         76.51     57.81         80.28  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что не обязательно ставить на все события одинаковую сумму. Оказывается, существует такой критерий Келли, который говорит сколько лучше поставить, в %, чтобы на дистанции быть в выйгрыше. cash_% = 100 ***** nu (BK_coef ***** prob-1)/(BK_coef-1)\n",
    "\n",
    "Так же введём предположение, что БК позволяют ставить сколь угодно большие и сколь угодно маленькие по размеру ставки, а так же ставки со сколь угодно большим количество дробных знаков(например 0.01403892551725 у.е.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nu - параметр доверия, от 0 до 1, чем он выше, тем больше можно потерять. На выходе число от 0 до 1, которое говорит, какую часть своих средств нужно ставить\n",
    "def Kelli(BK_coef, prob, nu):\n",
    "    return nu*(BK_coef*prob - 1)/(BK_coef - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_prediction_Kelli(data, prediction, prob, result, nu):\n",
    "    BK_coef = data[[\"B365A\", \"B365D\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"D\", \"H\"]\n",
    "    prob = pd.DataFrame(prob, columns = [\"A\", \"D\", \"H\"])\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        for adh in (\"A\", \"D\", \"H\"):\n",
    "            rate = Kelli(BK_coef.loc[i][adh], prob.loc[i][adh], nu)\n",
    "            if rate>0:\n",
    "                if result[i]==adh:\n",
    "                    cash = cash*(1 + rate*(BK_coef.loc[i][adh]-1))\n",
    "                else:\n",
    "                    cash = cash*(1-rate)\n",
    "        cash_history.append(cash)\n",
    "            \n",
    "    return cash_history\n",
    "\n",
    "def test_prediction_HA_Kelli(data, prediction, prob, result, nu):\n",
    "    BK_coef = data[[\"B365A\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"H\"]\n",
    "    prob = pd.DataFrame(prob, columns = [\"A\", \"H\"])\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        for ah in (\"A\", \"H\"):\n",
    "            rate = Kelli(BK_coef.loc[i][ah], prob.loc[i][ah], nu)\n",
    "            if rate>0:\n",
    "                if result[i]==ah:\n",
    "                    cash = cash + rate*cash*(BK_coef.loc[i][ah]-1)\n",
    "                else:\n",
    "                    cash = cash*(1-rate)\n",
    "        cash_history.append(cash)\n",
    "            \n",
    "    return cash_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nu = 0.1\n",
    "def make_prediction(nu):\n",
    "    Result_Kelli = pd.DataFrame()\n",
    "    Result_Kelli[\"Cash_GB\"] = test_prediction_Kelli(test, prediction_GB, proba_GB, test_Y, nu)\n",
    "    Result_Kelli[\"Cash_GB2\"] = test_prediction_Kelli(test2, prediction_GB2, proba_GB2, test_Y2, nu)\n",
    "    Result_Kelli[\"Cash_GB3\"] = test_prediction_Kelli(test3, prediction_GB3, proba_GB3, test_Y3, nu)\n",
    "    Result_Kelli[\"Cash_LR\"] = test_prediction_Kelli(test, prediction_LR, proba_LR, test_Y, nu)\n",
    "    Result_Kelli[\"Cash_LR_fix\"] = test_prediction_Kelli(test, prediction_LR_fix, proba_LR_fix, test_Y, nu)\n",
    "    Result_Kelli[\"Cash_LR2\"] = test_prediction_Kelli(test2, prediction_LR2, proba_LR2, test_Y2, nu)\n",
    "    Result_Kelli[\"Cash_LR2_fix\"] = test_prediction_Kelli(test2, prediction_LR2_fix, proba_LR2_fix, test_Y2, nu)\n",
    "    Result_Kelli[\"Cash_LR3\"] = test_prediction_Kelli(test3, prediction_LR3, proba_LR3, test_Y3, nu)\n",
    "    Result_Kelli[\"Cash_LR3_fix\"] = test_prediction_Kelli(test3, prediction_LR3_fix, proba_LR_fix, test_Y3, nu)\n",
    "    return Result_Kelli\n",
    "\n",
    "def make_prediction_HA(nu):\n",
    "    Result_HA_Kelli = pd.DataFrame()\n",
    "    Result_HA_Kelli[\"Cash_GB2_HA\"] = test_prediction_HA_Kelli(test2_HA, prediction_GB2_HA, proba_GB2_HA, test_Y2_HA, nu)\n",
    "    Result_HA_Kelli[\"Cash_GB3_HA\"] = test_prediction_HA_Kelli(test3_HA, prediction_GB3_HA, proba_GB3_HA, test_Y3_HA, nu)\n",
    "    Result_HA_Kelli[\"Cash_LR2_HA\"] = test_prediction_HA_Kelli(test2_HA, prediction_LR2_HA, proba_LR2_HA, test_Y2_HA, nu)\n",
    "    Result_HA_Kelli[\"Cash_LR3_HA\"] = test_prediction_HA_Kelli(test3_HA, prediction_LR3_HA, proba_LR3_HA, test_Y3_HA, nu)\n",
    "    return Result_HA_Kelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cash_GB   Cash_GB2  Cash_GB3    Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
      "1139  27.767301  26.346442  63.56728  29.155743    29.155743  45.59167   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139      45.59167  88.309358     29.155743  \n",
      "\n",
      "\n",
      "       Cash_GB  Cash_GB2   Cash_GB3   Cash_LR  Cash_LR_fix   Cash_LR2  \\\n",
      "1139  3.274868  3.595261  34.932227  4.530052     4.530052  14.982678   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139     14.982678  73.495542      4.530052  \n",
      "\n",
      "\n",
      "       Cash_GB  Cash_GB2   Cash_GB3   Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
      "1139  0.182376  0.273478  16.738492  0.399999     0.399999  3.616156   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139      3.616156  57.640721      0.399999  \n",
      "\n",
      "\n",
      "      Cash_GB  Cash_GB2  Cash_GB3  Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
      "1139  0.00518  0.012245  7.043898  0.02107      0.02107  0.650797   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139      0.650797  42.588316       0.02107  \n",
      "\n",
      "\n",
      "       Cash_GB  Cash_GB2  Cash_GB3   Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
      "1139  0.000079  0.000336   2.61895  0.000687     0.000687  0.088417   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139      0.088417  29.629467      0.000687  \n",
      "\n",
      "\n",
      "           Cash_GB  Cash_GB2  Cash_GB3   Cash_LR  Cash_LR_fix  Cash_LR2  \\\n",
      "1139  6.889025e-07  0.000006  0.864703  0.000014     0.000014  0.009159   \n",
      "\n",
      "      Cash_LR2_fix  Cash_LR3  Cash_LR3_fix  \n",
      "1139      0.009159  19.39525      0.000014  \n",
      "\n",
      "\n",
      "           Cash_GB      Cash_GB2  Cash_GB3       Cash_LR   Cash_LR_fix  \\\n",
      "1139  3.489773e-09  6.629606e-08  0.254629  1.941470e-07  1.941470e-07   \n",
      "\n",
      "      Cash_LR2  Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139  0.000729      0.000729  11.932648  1.941470e-07  \n",
      "\n",
      "\n",
      "           Cash_GB      Cash_GB2  Cash_GB3       Cash_LR   Cash_LR_fix  \\\n",
      "1139  1.061251e-11  4.977089e-10   0.06712  1.751296e-09  1.751296e-09   \n",
      "\n",
      "      Cash_LR2  Cash_LR2_fix  Cash_LR3  Cash_LR3_fix  \n",
      "1139  0.000045      0.000045   6.88997  1.751296e-09  \n",
      "\n",
      "\n",
      "           Cash_GB      Cash_GB2  Cash_GB3       Cash_LR   Cash_LR_fix  \\\n",
      "1139  1.978007e-14  2.518075e-12  0.015887  1.064509e-11  1.064509e-11   \n",
      "\n",
      "      Cash_LR2  Cash_LR2_fix  Cash_LR3  Cash_LR3_fix  \n",
      "1139  0.000002      0.000002  3.726522  1.064509e-11  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(make_prediction(i/10)[-1:])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    41.254839    91.725419    67.219556   107.364131\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    11.016621    77.385102    32.753765   111.691555\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     1.960649    60.308489    11.720449   112.526762\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     0.236988    43.566532     3.105557   109.707681\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     0.019673    29.253948     0.611906   103.395744\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     0.001127    18.299383     0.089704    94.061193\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     0.000045    10.682521     0.009754    82.425408\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     0.000001     5.827649     0.000781    69.370043\n",
      "      Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855  2.216237e-08     2.974044     0.000046    55.828629\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(make_prediction_HA(i/10)[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Италия, Серия А"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим насколько это будет правдой в другом дивизионе. Для этого построим лучшие модели и посмотрим к чему это всё приведет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/RomanSivolobtsev/Documents/Статистика Серии А/\"\n",
    "start_year = 2005\n",
    "start_seasonses4 = pd.DataFrame() # 2 сезона для начальной выборки генерирования фич\n",
    "train4 = pd.DataFrame() # 7 сезонов по которым будет обучаться модель \n",
    "test4 = pd.DataFrame() # 3 сезона для прогнозов\n",
    "\n",
    "for i in range(2):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    I1 = pd.read_csv(folder + 'I1.csv', index_col=False)\n",
    "    I2 = pd.read_csv(folder + 'I2.csv', index_col=False)\n",
    "    start_seasonses4 = start_seasonses4.append([I1, I2], ignore_index=True)\n",
    "\n",
    "for i in range(2, 9):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    I1 = pd.read_csv(folder + 'I1.csv', index_col=False)\n",
    "    train4 = train4.append([I1], ignore_index=True)\n",
    "    \n",
    "for i in range(9, 12):\n",
    "    folder = path + str(start_year + i) + \"-\" + str(start_year + i + 1) + \"/\"\n",
    "    I1 = pd.read_csv(folder + 'I1.csv', index_col=False)\n",
    "    test4 = test4.append(I1, ignore_index=True)\n",
    "    \n",
    "train4 = train4[pd.notnull(train4['Div'])]\n",
    "test4 = test4[pd.notnull(test4['Div'])] # некоторые файлы в конце импортируют пустую строчку, эта для их отлова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test4.index = [x for x in range(len(test4))]\n",
    "train4.index = [x for x in range(len(train4))] # перебивка индексов, чтобы не было проблем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных по Итальянской лиге нету имён рефери. Чуть чуть переформируем выборку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team1 - Home Team, Team2 - Away Team\n",
    "\n",
    "def generate_mix_features2(Team1_HomeMatch, Team1_AwayMatch, Team2_HomeMatch, Team2_AwayMatch, BK):\n",
    "    match_significance = np.array([1, 0.7, 0.5, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05])\n",
    "    match_significance = match_significance/sum(match_significance) # нормировка коэффициентов\n",
    "    \n",
    "    Team1_FTHG_average = Team1_HomeMatch['FTHG'].mean() # среднее количество забитых голов домашней командны в её домашних матчах\n",
    "    Team2_FTAG_average = Team2_AwayMatch['FTAG'].mean() # среднее количество забитых голов гостевой команды в её гостевых матчах \n",
    "    FTG_nearest_diff = sum(Team1_HomeMatch['FTHG'][-10:]*match_significance) - sum(Team2_AwayMatch['FTAG'][-10:]*match_significance)\n",
    "   \n",
    "    FTLG_nearest_diff = sum(Team1_AwayMatch['FTHG'][-10:]*match_significance)-sum(Team2_HomeMatch['FTAG'][-10:]*match_significance) \n",
    "    # разница пропущенных голов домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    S_nearest_diff = sum(Team1_HomeMatch['HS'][-10:]*match_significance)-sum(Team2_AwayMatch['AS'][-10:]*match_significance) \n",
    "    # разница ударов по воротам домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "    \n",
    "    ST_nearest_diff = sum(Team1_HomeMatch['HST'][-10:]*match_significance) - sum(Team2_AwayMatch['AST'][-10:]*match_significance) \n",
    "    # разница ударов в створ ворот домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости\n",
    "\n",
    "    C_nearest_diff = sum(Team1_HomeMatch['HC'][-10:]*match_significance) -sum(Team2_AwayMatch['AC'][-10:]*match_significance) \n",
    "    # разница угловых домашней и гостевой команд в их последних 10 матчах с коэфициентами значимости   \n",
    "\n",
    "    Team1_HFTR_nearest = sum(Team1_HomeMatch['FTR'][-30:].replace(to_replace=[\"H\", \"D\", \"A\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 домашних матчей \n",
    "    Team2_AFTR_nearest = sum(Team2_AwayMatch['FTR'][-30:].replace(to_replace=[\"A\", \"D\", \"H\"], value=[3, 1, 0])) #количество набранных очков командой за последних 20 гостевых матчей\n",
    "                    \n",
    "    BK_Teams_diff = max(BK[[\"B365H\", \"BWH\", \"IWH\", \"LBH\", \"WHH\", \"VCH\"]]) - max(BK[[\"B365A\", \"BWA\", \"IWA\", \"LBA\", \"WHA\", \"VCA\"]])\n",
    "    # разница коэффициентов на победу домашней и гостевой команд\n",
    "    BK_Draw = max(BK[[\"B365D\", \"BWD\", \"IWD\", \"LBD\", \"WHD\", \"VCD\"]]) # лучший коэффициент на ничью\n",
    "\n",
    "    return [Team1_FTHG_average, Team2_FTAG_average, FTG_nearest_diff, FTLG_nearest_diff, S_nearest_diff, ST_nearest_diff, \n",
    "            C_nearest_diff, Team1_HFTR_nearest, Team2_AFTR_nearest, BK_Teams_diff, BK_Draw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features4 = [\"Team1_FTHG_average\", \"Team2_FTAG_average\", \"FTG_nearest_diff\", \"FTLG_nearest_diff\", \"S_nearest_diff\", \"ST_nearest_diff\", \n",
    "             \"C_nearest_diff\", \"Team1_HFTR_nearest\", \"Team2_AFTR_nearest\", \"BK_Teams_diff\", \"BK_Draw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Teams4 = train4['HomeTeam'].append(test4['HomeTeam']).unique() # Список всех команд за 8 лет в 2 английских дивизионах\n",
    "Teams_HomeData4 = {Teams4[i]: start_seasonses4[start_seasonses4[\"HomeTeam\"] == Teams4[i]] for i in range(len(Teams4))} # домашние матчи каждой прогназируемой команды\n",
    "Teams_AwayData4 = {Teams4[i]: start_seasonses4[start_seasonses4[\"AwayTeam\"] == Teams4[i]] for i in range(len(Teams4))} # гостевые матчи каждой прогназируемой команды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X4 = pd.DataFrame(columns = features4)\n",
    "train_Y4 = []\n",
    "test_X4 = pd.DataFrame(columns = features4)\n",
    "test_Y4 = []\n",
    "\n",
    "# выборка на 7 сезонах для обучения\n",
    "\n",
    "for i in range(len(train4)):\n",
    "    row = train4.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    \n",
    "    if (len(Teams_HomeData4[Team1]) >= 10) & (len(Teams_AwayData4[Team2]) >= 10):\n",
    "    # если команда только влетела в каком-то сезоне, то на неё нет достаточно информации\n",
    "        BK =  row[attribute_bk]\n",
    "        feature = generate_mix_features2(Teams_HomeData4[Team1], Teams_AwayData4[Team1], Teams_HomeData4[Team2], \n",
    "                                        Teams_AwayData4[Team2], BK)\n",
    "        train_X4.loc[i] = feature\n",
    "        train_Y4.append(train4[\"FTR\"].loc[i])\n",
    "        \n",
    "    Teams_HomeData4[Team1] = Teams_HomeData4[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData4[Team2] = Teams_AwayData4[Team2].append(row, ignore_index=True)\n",
    "\n",
    "# выборка на 3 неполных сезонах для построения прогнозов\n",
    "\n",
    "for i in range(len(test4)):\n",
    "    row = test4.ix[i]\n",
    "    Team1 = row[\"HomeTeam\"]\n",
    "    Team2 = row[\"AwayTeam\"]\n",
    "    BK =  row[attribute_bk]\n",
    "    \n",
    "    if (len(Teams_HomeData4[Team1]) >= 10) & (len(Teams_AwayData4[Team2]) >= 10) & (len(Teams_HomeData4[Team2]) >= 10) & (len(Teams_AwayData4[Team1]) >= 10):\n",
    "    # если команда только влетела в каком-то сезоне, то на неё нет достаточно информации\n",
    "        BK =  row[attribute_bk]\n",
    "        feature = generate_mix_features2(Teams_HomeData4[Team1], Teams_AwayData4[Team1], Teams_HomeData4[Team2], \n",
    "                                         Teams_AwayData4[Team2], BK)\n",
    "        test_X4.loc[i] = feature\n",
    "        test_Y4.append(test4[\"FTR\"].loc[i])\n",
    "    else:\n",
    "        test4 = test4.drop(i)\n",
    "        \n",
    "    \n",
    "    Teams_HomeData4[Team1] = Teams_HomeData4[Team1].append(row, ignore_index=True) #после прогноза матча, его исход нужно добавить в данные по прошедшим матчам\n",
    "    Teams_AwayData4[Team2] = Teams_AwayData4[Team2].append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#реформируем данные\n",
    "\n",
    "train_X4 = train_X4.replace(to_replace=\"NaN\", value=0) \n",
    "test_X4 = test_X4.replace(to_replace=\"NaN\", value=0) \n",
    "\n",
    "test4.index = [x for x in range(len(test4))]\n",
    "train4.index = [x for x in range(len(train4))]\n",
    "\n",
    "[train_X4_HA, train_Y4_HA] = reformate_data(train_X4, train_Y4)\n",
    "[test_X4_HA, test_Y4_HA] = reformate_data(test_X4, test_Y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\item GB = GradientBoostingClassifier(min_samples_split = 2, max_depth = 3, learning_rate = 0.03, random_state = 42, min_samples_leaf = 50, n_estimators = 50, subsample=0.9)\n",
    "\n",
    "\\item GB2 = GradientBoostingClassifier(min_samples_split = 1, max_depth = 3, learning_rate = 0.03, random_state = 42, min_samples_leaf = 25, n_estimators = 30)\n",
    "\n",
    "\\item GB3 = GradientBoostingClassifier(min_samples_split = 2, max_depth = 4, learning_rate = 0.03, min_samples_leaf = 50, subsample = 0.9, n_estimators = 50, random_state = 42)\n",
    "\n",
    "\\item LR = LogisticRegression(random_state = 42, C=0.4, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "\n",
    "\\item LR2 = LogisticRegression(random_state = 42, C=0.6, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "\n",
    "\\item LR3 = LogisticRegression(random_state = 42, C=0.4, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "\n",
    "\\item GB2_HA = GradientBoostingClassifier(min_samples_split = 2, max_depth = 4, learning_rate = 0.03, min_samples_leaf = 50, n_estimators = 70, subsample=0.9, random_state=42)\n",
    "\n",
    "\\item LR2_HA = LogisticRegression(random_state = 42, C=0.6, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "\n",
    "\\item GB3_HA = GradientBoostingClassifier(min_samples_split = 1, max_depth = 3, learning_rate = 0.04, min_samples_leaf = 30, n_estimators = 50, subsample=0.9, random_state=42)\n",
    "\n",
    "\\item LR3_HA = LogisticRegression(random_state = 42, C=0.6, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "\n",
    "\\item GB4_HA = GradientBoostingClassifier(min_samples_split = 2, max_depth = 3, learning_rate = 0.03, min_samples_leaf = 70, n_estimators = 50, subsample=0.9, random_state=42)\n",
    "\n",
    "\\item LR4_HA = LogisticRegression(random_state = 42, C=0.5, tol=0.0001, max_iter=50, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.03, loss='deviance',\n",
      "              max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=30, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              presort='auto', random_state=None, subsample=0.9, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'min_samples_split': [1, 2], 'max_depth': [2, 3, 4], 'learning_rate': [0.03, 0.04],\n",
    "                     'min_samples_leaf':[30, 50, 70], 'n_estimators': [30, 50, 70, 90], \"subsample\": [1, 0.9]}]\n",
    "\n",
    "GB_classifier4_HA = GridSearchCV(GradientBoostingClassifier(), tuned_parameters)\n",
    "GB_classifier4_HA.fit(train_X4_HA, train_Y4_HA)\n",
    "print(GB_classifier4_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.748443983402\n",
      "На тестовой выборке: 0.739184177998\n",
      "[[178 143]\n",
      " [ 68 420]]\n"
     ]
    }
   ],
   "source": [
    "GB_classifier4_HA = GradientBoostingClassifier(min_samples_split = 2, max_depth = 3, learning_rate = 0.05, \n",
    "                                               min_samples_leaf = 100, n_estimators = 50, subsample=0.9, random_state=42)\n",
    "GB_classifier4_HA.fit(train_X4_HA, train_Y4_HA)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y4_HA, GB_classifier4_HA.predict(train_X4_HA))))\n",
    "\n",
    "proba_GB4_HA = GB_classifier4_HA.predict_proba(test_X4_HA)\n",
    "prediction_GB4_HA = GB_classifier4_HA.predict(test_X4_HA)\n",
    "\n",
    "result_GB4_HA = pd.DataFrame()\n",
    "result_GB4_HA[0] = proba_GB4_HA[:,0]\n",
    "result_GB4_HA[1] = proba_GB4_HA[:,1]\n",
    "result_GB4_HA[2] = prediction_GB4_HA\n",
    "result_GB4_HA[3] = test_Y4_HA\n",
    "\n",
    "result_GB4_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_GB4_HA = accuracy_score(test_Y4_HA, result_GB4_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_GB4_HA))\n",
    "\n",
    "print(confusion_matrix(result_GB4_HA[\"result\"], result_GB4_HA[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.6, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.4, 0.6, 0.8, 1, 1.5], 'tol': [0.0001, 0.0002, 0.0003], 'max_iter': [50, 100, 150],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'liblinear']}]\n",
    "\n",
    "LR_classifier4_HA = GridSearchCV(LogisticRegression(), tuned_parameters)\n",
    "LR_classifier4_HA.fit(train_X4_HA, train_Y4_HA)\n",
    "print(LR_classifier4_HA.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На тренировочной выборке: 0.726659751037\n",
      "На тестовой выборке: 0.737948084054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[180, 141],\n",
       "       [ 71, 417]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier4_HA = LogisticRegression(random_state = 42, C=0.5, tol=0.0001, max_iter=50, solver='lbfgs')\n",
    "LR_classifier4_HA.fit(train_X4_HA, train_Y4_HA)\n",
    "\n",
    "print(\"На тренировочной выборке: \" + str(accuracy_score(train_Y4_HA, LR_classifier4_HA.predict(train_X4_HA))))\n",
    "\n",
    "proba_LR4_HA = LR_classifier4_HA.predict_proba(test_X4_HA)\n",
    "prediction_LR4_HA = LR_classifier4_HA.predict(test_X4_HA)\n",
    "\n",
    "result_LR4_HA = pd.DataFrame()\n",
    "result_LR4_HA[0] = proba_LR4_HA[:,0]\n",
    "result_LR4_HA[1] = proba_LR4_HA[:,1]\n",
    "result_LR4_HA[2] = prediction_LR4_HA\n",
    "result_LR4_HA[3] = test_Y4_HA\n",
    "\n",
    "result_LR4_HA.columns = [\"A\", \"H\", \"prediction\", \"result\"]\n",
    "\n",
    "score_LR4_HA = accuracy_score(test_Y4_HA, result_LR4_HA[\"prediction\"])\n",
    "print(\"На тестовой выборке: \" + str(score_LR4_HA))\n",
    "\n",
    "confusion_matrix(test_Y4_HA, result_LR4_HA[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test4_HA = test4[(test4[\"FTR\"]==\"A\") | (test4[\"FTR\"]==\"H\")][[\"B365H\", \"B365D\", \"B365A\"]]\n",
    "test4_HA.index = [x for x in range(len(test4_HA))]\n",
    "for i in range(len(test4_HA)):\n",
    "    row = test4_HA.loc[i]\n",
    "    test4_HA.loc[i] = reformate_coef(row[\"B365H\"], row[\"B365D\"], row[\"B365A\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     74.95377    91.280557\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    53.418087    80.866389\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     36.18414    69.397936\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    23.283975    57.556588\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     14.22385    45.997429\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     8.242255    35.287714\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     4.526085    25.859276\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808      2.35262    17.980726\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808     1.155995    11.751952\n"
     ]
    }
   ],
   "source": [
    "def make_prediction_Italy_HA(nu):\n",
    "    Result2_HA_Kelli = pd.DataFrame()\n",
    "    Result2_HA_Kelli[\"Cash_GB4_HA\"] = test_prediction_HA_Kelli(test4_HA, prediction_GB4_HA, proba_GB4_HA, test_Y4_HA, nu)\n",
    "    Result2_HA_Kelli[\"Cash_LR4_HA\"] = test_prediction_HA_Kelli(test4_HA, prediction_LR4_HA, proba_LR4_HA, test_Y4_HA, nu)\n",
    "    return Result2_HA_Kelli\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(make_prediction_Italy_HA(i/10)[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Порог уверенности. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В редких случаях получаем + значения. А теперь попробуем ставить не на каждое событие, а на те, на которые наша вероятность больше заданного значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_prediction_Kelli2(data, prediction, prob, result, nu, step):\n",
    "    BK_coef = data[[\"B365A\", \"B365D\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"D\", \"H\"]\n",
    "    prob = pd.DataFrame(prob, columns = [\"A\", \"D\", \"H\"])\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prob.loc[i][prediction[i]]>step:\n",
    "            rate = Kelli(BK_coef.loc[i][prediction[i]], prob.loc[i][prediction[i]], nu)\n",
    "            if rate>0:\n",
    "                if result[i]==prediction[i]:\n",
    "                    cash = cash*(1 + rate*(BK_coef[result[i]].loc[i]-1))\n",
    "                else:\n",
    "                    cash = cash*(1-rate)\n",
    "            cash_history.append(cash)\n",
    "        else:\n",
    "            cash_history.append(cash)\n",
    "            \n",
    "    return cash_history\n",
    "\n",
    "def test_prediction_HA_Kelli2(data, prediction, prob, result, nu, step):\n",
    "    BK_coef = data[[\"B365A\", \"B365H\"]]\n",
    "    BK_coef.columns = [\"A\", \"H\"]\n",
    "    prob = pd.DataFrame(prob, columns = [\"A\", \"H\"])\n",
    "    cash = 100 \n",
    "    cash_history = []\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prob.loc[i][prediction[i]]>step:\n",
    "            rate = Kelli(BK_coef.loc[i][prediction[i]], prob.loc[i][prediction[i]], nu)\n",
    "            if rate>0:\n",
    "                if result[i]==prediction[i]:\n",
    "                    cash = cash + rate*cash*(BK_coef[result[i]].loc[i]-1)\n",
    "                else:\n",
    "                    cash = cash*(1-rate)\n",
    "            cash_history.append(cash)\n",
    "        else:\n",
    "            cash_history.append(cash)\n",
    "            \n",
    "            \n",
    "    return cash_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nu = 0.1\n",
    "def make_prediction2(nu, step):\n",
    "    Result_Kelli = pd.DataFrame()\n",
    "    Result_Kelli[\"Cash_GB\"] = test_prediction_Kelli2(test, prediction_GB, proba_GB, test_Y, nu, step)\n",
    "    Result_Kelli[\"Cash_GB2\"] = test_prediction_Kelli2(test2, prediction_GB2, proba_GB2, test_Y2, nu, step)\n",
    "    Result_Kelli[\"Cash_GB3\"] = test_prediction_Kelli2(test3, prediction_GB3, proba_GB3, test_Y3, nu, step)\n",
    "    Result_Kelli[\"Cash_LR\"] = test_prediction_Kelli2(test, prediction_LR, proba_LR, test_Y, nu, step)\n",
    "    Result_Kelli[\"Cash_LR_fix\"] = test_prediction_Kelli2(test, prediction_LR_fix, proba_LR_fix, test_Y, nu, step)\n",
    "    Result_Kelli[\"Cash_LR2\"] = test_prediction_Kelli2(test2, prediction_LR2, proba_LR2, test_Y2, nu, step)\n",
    "    Result_Kelli[\"Cash_LR2_fix\"] = test_prediction_Kelli2(test2, prediction_LR2_fix, proba_LR2_fix, test_Y2, nu, step)\n",
    "    Result_Kelli[\"Cash_LR3\"] = test_prediction_Kelli2(test3, prediction_LR3, proba_LR3, test_Y3, nu, step)\n",
    "    Result_Kelli[\"Cash_LR3_fix\"] = test_prediction_Kelli2(test3, prediction_LR3_fix, proba_LR_fix, test_Y3, nu, step)\n",
    "    return Result_Kelli\n",
    "\n",
    "def make_prediction_HA2(nu, step):\n",
    "    Result_HA_Kelli = pd.DataFrame()\n",
    "    Result_HA_Kelli[\"Cash_GB2_HA\"] = test_prediction_HA_Kelli2(test2_HA, prediction_GB2_HA, proba_GB2_HA, test_Y2_HA, nu, step)\n",
    "    Result_HA_Kelli[\"Cash_GB3_HA\"] = test_prediction_HA_Kelli2(test3_HA, prediction_GB3_HA, proba_GB3_HA, test_Y3_HA, nu, step)\n",
    "    Result_HA_Kelli[\"Cash_LR2_HA\"] = test_prediction_HA_Kelli2(test2_HA, prediction_LR2_HA, proba_LR2_HA, test_Y2_HA, nu, step)\n",
    "    Result_HA_Kelli[\"Cash_LR3_HA\"] = test_prediction_HA_Kelli2(test3_HA, prediction_LR3_HA, proba_LR3_HA, test_Y3_HA, nu, step)\n",
    "    return Result_HA_Kelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Cash_GB   Cash_GB2   Cash_GB3    Cash_LR  Cash_LR_fix   Cash_LR2  \\\n",
      "1139  102.774183  88.611057  77.997054  49.712072    57.574778  50.632208   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139     54.640977  92.050305     89.324732  \n",
      "\n",
      "\n",
      "        Cash_GB   Cash_GB2   Cash_GB3    Cash_LR  Cash_LR_fix   Cash_LR2  \\\n",
      "1139  68.513891  83.805021  83.552552  59.213223    60.796344  61.189715   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139     60.796315  98.995471     90.174557  \n",
      "\n",
      "\n",
      "        Cash_GB   Cash_GB2   Cash_GB3    Cash_LR  Cash_LR_fix   Cash_LR2  \\\n",
      "1139  99.820824  85.766284  85.713698  88.002924    88.002924  77.286992   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139     77.286992  98.475865     89.344727  \n",
      "\n",
      "\n",
      "       Cash_GB  Cash_GB2   Cash_GB3     Cash_LR  Cash_LR_fix   Cash_LR2  \\\n",
      "1139  104.1669  97.55724  84.463258  104.190714   104.190714  86.892166   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139     86.892166  100.03454    107.282354  \n",
      "\n",
      "\n",
      "        Cash_GB   Cash_GB2   Cash_GB3     Cash_LR  Cash_LR_fix    Cash_LR2  \\\n",
      "1139  104.00577  97.187824  93.483839  118.571847   118.571847  102.809336   \n",
      "\n",
      "      Cash_LR2_fix  Cash_LR3  Cash_LR3_fix  \n",
      "1139    102.809336  98.72392    118.571847  \n",
      "\n",
      "\n",
      "         Cash_GB   Cash_GB2   Cash_GB3    Cash_LR  Cash_LR_fix    Cash_LR2  \\\n",
      "1139  100.150106  98.055301  102.32566  96.302264    96.302264  106.828181   \n",
      "\n",
      "      Cash_LR2_fix    Cash_LR3  Cash_LR3_fix  \n",
      "1139    106.828181  100.829238     96.302264  \n",
      "\n",
      "\n",
      "      Cash_GB  Cash_GB2    Cash_GB3  Cash_LR  Cash_LR_fix    Cash_LR2  \\\n",
      "1139      100       100  101.344169      100          100  105.880123   \n",
      "\n",
      "      Cash_LR2_fix   Cash_LR3  Cash_LR3_fix  \n",
      "1139    105.880123  97.344102           100  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(7, 14):\n",
    "    print(make_prediction2(0.1, i/20)[-1:])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    55.105978    96.033972      77.1504    91.176184\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    53.027305   100.799345    84.460969    95.893741\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    59.391714   109.363463    98.158238    99.288761\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    75.497042   107.698116   117.083408    96.338124\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    88.160944   103.964701    98.373995    96.817576\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855    92.868065   101.864303    81.681863    97.394352\n",
      "\n",
      "\n",
      "     Cash_GB2_HA  Cash_GB3_HA  Cash_LR2_HA  Cash_LR3_HA\n",
      "855     98.87444   100.719312   101.120247    97.416719\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(11, 18):\n",
    "    print(make_prediction_HA2(0.1, i/20)[-1:])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тоже самое для итальянской лиги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    120.15281   110.822315\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808   108.380281    91.115006\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808   100.808836    94.250619\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    109.26776    84.688091\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808   115.981203     81.77196\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    111.26536     80.43428\n",
      "     Cash_GB4_HA  Cash_LR4_HA\n",
      "808    96.323382    77.171063\n"
     ]
    }
   ],
   "source": [
    "def make_prediction_Italy_HA2(nu, step):\n",
    "    Result2_HA_Kelli = pd.DataFrame()\n",
    "    Result2_HA_Kelli[\"Cash_GB4_HA\"] = test_prediction_HA_Kelli2(test4_HA, prediction_GB4_HA, proba_GB4_HA, test_Y4_HA, nu, step)\n",
    "    Result2_HA_Kelli[\"Cash_LR4_HA\"] = test_prediction_HA_Kelli2(test4_HA, prediction_LR4_HA, proba_LR4_HA, test_Y4_HA, nu, step)\n",
    "    return Result2_HA_Kelli\n",
    "\n",
    "for i in range(11,18):\n",
    "    print(make_prediction_Italy_HA2(0.2, 0.68)[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(make_prediction_HA2(0.2, i/20)[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запись данных, для графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-113-af36c20c5708>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-113-af36c20c5708>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    accuracy_score(test_Y, prediction_GB)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#     Result_Kelli[\"Cash_GB\"] = test_prediction_Kelli2(test, prediction_GB, proba_GB, test_Y, nu, step)\n",
    "#     Result_Kelli[\"Cash_GB2\"] = test_prediction_Kelli2(test2, prediction_GB2, proba_GB2, test_Y2, nu, step)\n",
    "#     Result_Kelli[\"Cash_GB3\"] = test_prediction_Kelli2(test3, prediction_GB3, proba_GB3, test_Y3, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR\"] = test_prediction_Kelli2(test, prediction_LR, proba_LR, test_Y, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR_fix\"] = test_prediction_Kelli2(test, prediction_LR_fix, proba_LR_fix, test_Y, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR2\"] = test_prediction_Kelli2(test2, prediction_LR2, proba_LR2, test_Y2, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR2_fix\"] = test_prediction_Kelli2(test2, prediction_LR2_fix, proba_LR2_fix, test_Y2, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR3\"] = test_prediction_Kelli2(test3, prediction_LR3, proba_LR3, test_Y3, nu, step)\n",
    "#     Result_Kelli[\"Cash_LR3_fix\"] = test_prediction_Kelli2(test3, prediction_LR3_fix, proba_LR_fix, test_Y3, nu, step)\n",
    "\n",
    "#     Result_HA_Kelli[\"Cash_GB2_HA\"] = test_prediction_HA_Kelli2(test2_HA, prediction_GB2_HA, proba_GB2_HA, test_Y2_HA, nu, step)\n",
    "#     Result_HA_Kelli[\"Cash_GB3_HA\"] = test_prediction_HA_Kelli2(test3_HA, prediction_GB3_HA, proba_GB3_HA, test_Y3_HA, nu, step)\n",
    "#     Result_HA_Kelli[\"Cash_LR2_HA\"] = test_prediction_HA_Kelli2(test2_HA, prediction_LR2_HA, proba_LR2_HA, test_Y2_HA, nu, step)\n",
    "#     Result_HA_Kelli[\"Cash_LR3_HA\"] = test_prediction_HA_Kelli2(test3_HA, prediction_LR3_HA, proba_LR3_HA, test_Y3_HA, nu, step)\n",
    "#     accuracy_score(test_Y, prediction_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GB</th>\n",
       "      <th>GB2</th>\n",
       "      <th>GB3</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_fix</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LR2_fix</th>\n",
       "      <th>LR3</th>\n",
       "      <th>LR3_fix</th>\n",
       "      <th>GB2_HA</th>\n",
       "      <th>GB3_HA</th>\n",
       "      <th>GB4_HA</th>\n",
       "      <th>LR2_HA</th>\n",
       "      <th>LR3_HA</th>\n",
       "      <th>LR4_HA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.524561</td>\n",
       "      <td>0.538596</td>\n",
       "      <td>0.514912</td>\n",
       "      <td>0.514912</td>\n",
       "      <td>0.52193</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.535965</td>\n",
       "      <td>0.704439</td>\n",
       "      <td>0.716121</td>\n",
       "      <td>0.732034</td>\n",
       "      <td>0.699766</td>\n",
       "      <td>0.709112</td>\n",
       "      <td>0.733252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GB       GB2       GB3        LR    LR_fix      LR2   LR2_fix  \\\n",
       "0  0.517544  0.524561  0.538596  0.514912  0.514912  0.52193  0.531579   \n",
       "\n",
       "        LR3   LR3_fix    GB2_HA    GB3_HA    GB4_HA    LR2_HA    LR3_HA  \\\n",
       "0  0.535088  0.535965  0.704439  0.716121  0.732034  0.699766  0.709112   \n",
       "\n",
       "     LR4_HA  \n",
       "0  0.733252  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.DataFrame([[score_GB, score_GB2, score_GB3, score_LR, score_LR_fix, score_LR2, score_LR2_fix, score_LR3, \n",
    "                      score_LR3_fix, score_GB2_HA, score_GB3_HA, score_GB4_HA, score_LR2_HA, score_LR3_HA, score_LR4_HA]], \n",
    "                     columns = ['GB', 'GB2', 'GB3', 'LR', 'LR_fix', 'LR2', 'LR2_fix', 'LR3', 'LR3_fix', 'GB2_HA', 'GB3_HA',\n",
    "                                'GB4_HA', 'LR2_HA', 'LR3_HA', 'LR4_HA'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score.to_csv(\"score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cash = pd.DataFrame()\n",
    "for i in range(10, 18):\n",
    "    cash[i/20] = make_prediction_HA2(0.1, i/20).ix[855]\n",
    "\n",
    "cash.to_csv(\"cash.csv\")\n",
    "\n",
    "cash2 = pd.DataFrame()\n",
    "for i in range(6,14):\n",
    "    cash2[i/20] = make_prediction2(0.1, i/20).ix[1139]\n",
    "\n",
    "cash2.to_csv(\"cash2.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_prediction_Italy_HA2(0.2, 0.68).to_csv(\"italy.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>FTG_nearest_diff</th>\n",
       "      <th>FTLG_nearest_diff</th>\n",
       "      <th>S_nearest_diff</th>\n",
       "      <th>ST_nearest_diff</th>\n",
       "      <th>C_nearest_diff</th>\n",
       "      <th>Team1_HFTR_nearest</th>\n",
       "      <th>Team2_AFTR_nearest</th>\n",
       "      <th>Team1_HFTR_nearest2</th>\n",
       "      <th>Team2_AFTR_nearest2</th>\n",
       "      <th>Team1_HFTR_nearest3</th>\n",
       "      <th>Team2_AFTR_nearest3</th>\n",
       "      <th>Referee_HomeTeam_points</th>\n",
       "      <th>Referee_AwayTeam_points</th>\n",
       "      <th>Referee_Draw_points</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>-0.513889</td>\n",
       "      <td>1.861111</td>\n",
       "      <td>-2.527778</td>\n",
       "      <td>-3.847222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.447368</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.805556</td>\n",
       "      <td>2.319444</td>\n",
       "      <td>1.597222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.434783</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>-0.152778</td>\n",
       "      <td>1.486111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>3.430556</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.486111</td>\n",
       "      <td>4.458333</td>\n",
       "      <td>1.513889</td>\n",
       "      <td>5.041667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552632</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.190476</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>-0.861111</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.486111</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.421053</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>4.611111</td>\n",
       "      <td>1.819444</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.394737</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>6.152778</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.210526</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>-0.152778</td>\n",
       "      <td>3.819444</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.402778</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.184211</td>\n",
       "      <td>1.523810</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>14.152778</td>\n",
       "      <td>8.291667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1_FTHG_average  Team2_FTAG_average  FTG_nearest_diff  \\\n",
       "0            1.052632            1.131579         -0.513889   \n",
       "1            1.447368            0.894737          0.666667   \n",
       "2            1.434783            0.973684          0.277778   \n",
       "3            1.447368            1.052632          0.500000   \n",
       "4            1.552632            1.078947          0.597222   \n",
       "5            1.190476            1.184211          0.152778   \n",
       "6            1.421053            0.947368          0.166667   \n",
       "7            2.394737            0.973684          1.875000   \n",
       "8            2.210526            0.928571          1.833333   \n",
       "9            2.184211            1.523810          1.444444   \n",
       "\n",
       "   FTLG_nearest_diff  S_nearest_diff  ST_nearest_diff  C_nearest_diff  \\\n",
       "0           1.861111       -2.527778        -3.847222        0.416667   \n",
       "1           0.916667        1.805556         2.319444        1.597222   \n",
       "2          -0.152778        1.486111         0.055556        3.430556   \n",
       "3          -1.486111        4.458333         1.513889        5.041667   \n",
       "4           0.069444        2.750000         2.444444        2.041667   \n",
       "5          -0.861111        3.111111         3.833333        2.486111   \n",
       "6           0.486111        4.611111         1.819444        2.666667   \n",
       "7           0.236111        6.152778         4.250000        2.222222   \n",
       "8          -0.152778        3.819444         1.750000        1.402778   \n",
       "9          -0.083333       14.152778         8.291667        2.000000   \n",
       "\n",
       "   Team1_HFTR_nearest  Team2_AFTR_nearest  Team1_HFTR_nearest2  \\\n",
       "0                 7.0                 5.0                 19.0   \n",
       "1                 5.0                 4.0                 22.0   \n",
       "2                11.0                 3.0                 33.0   \n",
       "3                12.0                 7.0                 29.0   \n",
       "4                 6.0                 8.0                 27.0   \n",
       "5                13.0                10.0                 38.0   \n",
       "6                 9.0                 7.0                 22.0   \n",
       "7                10.0                 1.0                 34.0   \n",
       "8                 9.0                 7.0                 33.0   \n",
       "9                10.0                 5.0                 38.0   \n",
       "\n",
       "   Team2_AFTR_nearest2  Team1_HFTR_nearest3  Team2_AFTR_nearest3  \\\n",
       "0                 21.0                 45.0                 41.0   \n",
       "1                 12.0                 53.0                 28.0   \n",
       "2                  9.0                 59.0                 25.0   \n",
       "3                 18.0                 58.0                 34.0   \n",
       "4                 17.0                 47.0                 38.0   \n",
       "5                 20.0                 53.0                 32.0   \n",
       "6                 20.0                 43.0                 25.0   \n",
       "7                  6.0                 66.0                 15.0   \n",
       "8                 23.0                 74.0                 38.0   \n",
       "9                 14.0                 76.0                 38.0   \n",
       "\n",
       "   Referee_HomeTeam_points  Referee_AwayTeam_points  Referee_Draw_points  \\\n",
       "0                      0.8                      0.1                  0.1   \n",
       "1                      0.5                      0.5                  0.0   \n",
       "2                      0.4                      0.4                  0.2   \n",
       "3                      0.6                      0.1                  0.3   \n",
       "4                      0.5                      0.3                  0.2   \n",
       "5                      0.4                      0.2                  0.4   \n",
       "6                      0.4                      0.3                  0.3   \n",
       "7                      0.6                      0.2                  0.2   \n",
       "8                      0.5                      0.3                  0.2   \n",
       "9                      0.4                      0.2                  0.4   \n",
       "\n",
       "  result  \n",
       "0      A  \n",
       "1      A  \n",
       "2      D  \n",
       "3      H  \n",
       "4      A  \n",
       "5      H  \n",
       "6      A  \n",
       "7      H  \n",
       "8      H  \n",
       "9      D  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35514018691588783"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38/107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_FTHG_average</th>\n",
       "      <th>Team2_FTAG_average</th>\n",
       "      <th>FTG_nearest_diff</th>\n",
       "      <th>FTLG_nearest_diff</th>\n",
       "      <th>S_nearest_diff</th>\n",
       "      <th>ST_nearest_diff</th>\n",
       "      <th>C_nearest_diff</th>\n",
       "      <th>Team1_HFTR_nearest</th>\n",
       "      <th>Team2_AFTR_nearest</th>\n",
       "      <th>Team1_HFTR_nearest2</th>\n",
       "      <th>Team2_AFTR_nearest2</th>\n",
       "      <th>Team1_HFTR_nearest3</th>\n",
       "      <th>Team2_AFTR_nearest3</th>\n",
       "      <th>Referee_HomeTeam_points</th>\n",
       "      <th>Referee_AwayTeam_points</th>\n",
       "      <th>Referee_Draw_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.095068</td>\n",
       "      <td>0.080266</td>\n",
       "      <td>0.149117</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.034373</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.192861</td>\n",
       "      <td>0.208487</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.008513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team1_FTHG_average  Team2_FTAG_average  FTG_nearest_diff  \\\n",
       "0            0.053299            0.056274          0.025265   \n",
       "\n",
       "   FTLG_nearest_diff  S_nearest_diff  ST_nearest_diff  C_nearest_diff  \\\n",
       "0           0.095068        0.080266         0.149117        0.028472   \n",
       "\n",
       "   Team1_HFTR_nearest  Team2_AFTR_nearest  Team1_HFTR_nearest2  \\\n",
       "0            0.025056            0.008444             0.034373   \n",
       "\n",
       "   Team2_AFTR_nearest2  Team1_HFTR_nearest3  Team2_AFTR_nearest3  \\\n",
       "0             0.002671             0.192861             0.208487   \n",
       "\n",
       "   Referee_HomeTeam_points  Referee_AwayTeam_points  Referee_Draw_points  \n",
       "0                 0.018238                 0.013597             0.008513  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([GB_classifier2.feature_importances_], columns = train_X2.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(LR_classifier3.coef_).to_csv(\"www.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62981382082587811"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+2.71828**(-sum(LR_classifier.coef_[2]*test_X.loc[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2578037994329243"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(LR_classifier.coef_[0]*test_X.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team1_FTHG_average', 'Team2_FTAG_average', 'FTG_nearest_diff',\n",
       "       'FTLG_nearest_diff', 'S_nearest_diff', 'ST_nearest_diff',\n",
       "       'C_nearest_diff', 'Team1_HFTR_nearest', 'Team2_AFTR_nearest',\n",
       "       'Team1_HFTR_nearest2', 'Team2_AFTR_nearest2', 'Team1_HFTR_nearest3',\n",
       "       'Team2_AFTR_nearest3', 'Referee_HomeTeam_points',\n",
       "       'Referee_AwayTeam_points', 'Referee_Draw_points', 'result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>H</th>\n",
       "      <th>prediction</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208154</td>\n",
       "      <td>0.232641</td>\n",
       "      <td>0.559205</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251064</td>\n",
       "      <td>0.261954</td>\n",
       "      <td>0.486981</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249828</td>\n",
       "      <td>0.220604</td>\n",
       "      <td>0.529568</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211766</td>\n",
       "      <td>0.257565</td>\n",
       "      <td>0.530669</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249085</td>\n",
       "      <td>0.282688</td>\n",
       "      <td>0.468227</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.262253</td>\n",
       "      <td>0.335647</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.437333</td>\n",
       "      <td>0.259172</td>\n",
       "      <td>0.303496</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.206188</td>\n",
       "      <td>0.235222</td>\n",
       "      <td>0.558589</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.477390</td>\n",
       "      <td>0.252529</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.401924</td>\n",
       "      <td>0.233477</td>\n",
       "      <td>0.364599</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         D         H prediction result\n",
       "0  0.208154  0.232641  0.559205          H      H\n",
       "1  0.251064  0.261954  0.486981          H      D\n",
       "2  0.249828  0.220604  0.529568          H      A\n",
       "3  0.211766  0.257565  0.530669          H      A\n",
       "4  0.249085  0.282688  0.468227          H      A\n",
       "5  0.402100  0.262253  0.335647          A      D\n",
       "6  0.437333  0.259172  0.303496          A      A\n",
       "7  0.206188  0.235222  0.558589          H      H\n",
       "8  0.477390  0.252529  0.270081          A      A\n",
       "9  0.401924  0.233477  0.364599          A      A"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LR[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
